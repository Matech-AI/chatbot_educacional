#!/usr/bin/env python3
"""
Servidor RAG Independente - DNA da For√ßa AI
Este servidor fica sempre rodando para processamento de materiais e treinamento do modelo.
"""

import os
import logging
import asyncio
from pathlib import Path
from fastapi import FastAPI, HTTPException, BackgroundTasks, Request, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from contextlib import asynccontextmanager
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import uvicorn
from dotenv import load_dotenv
from uuid import uuid4
import time
import json
import zipfile
import tarfile
import tempfile
import aiohttp
from datetime import datetime

# Importar componentes RAG
from rag_system.rag_handler import RAGHandler, RAGConfig, Source
import chromadb
from chromadb.config import Settings
from chat_agents.educational_agent import router as educational_agent_router
# ========================================
# MODELS PYDANTIC
# ========================================


class Question(BaseModel):
    content: str


class Response(BaseModel):
    answer: str
    sources: List[dict]
    response_time: float


class ChatRequest(BaseModel):
    message: str
    thread_id: Optional[str] = None


class ProcessMaterialsRequest(BaseModel):
    force_reprocess: bool = False
    enable_educational_features: bool = True


class ProcessResponse(BaseModel):
    success: bool
    message: str


class QueryRequest(BaseModel):
    question: str
    user_level: str = "intermediate"


class QueryResponse(BaseModel):
    answer: str
    sources: List[dict]
    response_time: float


class AssistantConfigRequest(BaseModel):
    prompt: Optional[str] = None
    chunk_size: Optional[int] = None
    chunk_overlap: Optional[int] = None
    temperature: Optional[float] = None
    title: Optional[str] = None


class CompressLocalRequest(BaseModel):
    source_path: str = ".chromadb"
    output_filename: Optional[str] = None


# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Carregar vari√°veis de ambiente
load_dotenv()

# Vari√°veis globais
rag_handler = None
chroma_persist_dir = None
materials_dir = None

# Sistema de persist√™ncia para configura√ß√µes do assistente
assistant_configs_file = Path("data/assistant_configs.json")
assistant_configs = {}
current_assistant_config = None


def load_assistant_configs():
    """Carregar configura√ß√µes do assistente do arquivo"""
    global assistant_configs, current_assistant_config

    if assistant_configs_file.exists():
        try:
            with open(assistant_configs_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                assistant_configs = data.get('configs', {})
                current_assistant_config = data.get('current', None)
                logger.info(
                    f"‚úÖ Configura√ß√µes do assistente carregadas: {len(assistant_configs)} templates")
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar configura√ß√µes: {e}")
            assistant_configs = {}
            current_assistant_config = None


def save_assistant_configs():
    """Salvar configura√ß√µes do assistente no arquivo"""
    global assistant_configs, current_assistant_config

    try:
        # Criar diret√≥rio se n√£o existir
        assistant_configs_file.parent.mkdir(parents=True, exist_ok=True)

        data = {
            'configs': assistant_configs,
            'current': current_assistant_config,
            'last_updated': time.time()
        }

        with open(assistant_configs_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        logger.info(
            f"‚úÖ Configura√ß√µes do assistente salvas: {len(assistant_configs)} templates")
    except Exception as e:
        logger.error(f"‚ùå Erro ao salvar configura√ß√µes: {e}")


def get_default_templates():
    """Retornar templates padr√£o"""
    return {
        "Educa√ß√£o F√≠sica": {
            "name": "Assistente Educacional de Educa√ß√£o F√≠sica",
            "description": "Especializado em responder d√∫vidas sobre treinamento, fisiologia do exerc√≠cio e metodologia do ensino",
            "prompt": """Voc√™ √© um ASSISTENTE EDUCACIONAL especializado em EDUCA√á√ÉO F√çSICA. Seu objetivo √© auxiliar estudantes a compreender conceitos de treinamento, fisiologia do exerc√≠cio, biomec√¢nica e metodologia do ensino. Siga estas diretrizes:

1. CONTEXTO DO CURSO:
   - Padr√£o DNA-only: basear suas respostas exclusivamente nos materiais do DNA da For√ßa quando dispon√≠veis
   - Citar no formato: "M√≥dulo X, Aula Y ‚Äî 'T√≠tulo' (PDF), p. N" (n√£o inventar p√°gina; omitir quando n√£o existir metadado)
   - Nunca exibir caminhos de arquivos nem c√≥digos internos (ex.: M13A52)
   - Nunca inventar informa√ß√µes que n√£o estejam nos materiais do curso

2. ESTILO DE RESPOSTA:
   - Usar linguagem clara, t√©cnica mas acess√≠vel
   - Relacionar teoria com aplica√ß√£o pr√°tica no treinamento
   - Fornecer exemplos de exerc√≠cios e progress√µes quando apropriado
   - Explicar os princ√≠pios fisiol√≥gicos por tr√°s dos conceitos

3. CITA√á√ïES E FONTES:
   - Sempre indicar a origem no formato DNA e usar aspas para cita√ß√µes diretas
   - Se a pergunta n√£o puder ser respondida com os materiais dispon√≠veis, informar isto explicitamente e, se √∫til, adicionar bloco "Informa√ß√£o complementar (fora do acervo)"

4. ESTRAT√âGIAS PEDAG√ìGICAS:
   - Conectar conceitos te√≥ricos com aplica√ß√µes pr√°ticas no treinamento
   - Usar analogias relacionadas ao movimento humano
   - Incentivar an√°lise cr√≠tica de m√©todos de treinamento
   - Sugerir progress√µes e adapta√ß√µes para diferentes n√≠veis

Use {context}, {chat_history} e {question} como vari√°veis no template.""",
            "model": "gpt-4o-mini",
            "temperature": 0.1,
            "chunkSize": 2000,
            "chunkOverlap": 100,
            "retrievalSearchType": "mmr",
            "embeddingModel": "text-embedding-ada-002"
        },
        "Nutri√ß√£o Esportiva": {
            "name": "Assistente Educacional de Nutri√ß√£o Esportiva",
            "description": "Especializado em nutri√ß√£o aplicada ao esporte, suplementa√ß√£o e estrat√©gias alimentares para performance",
            "prompt": """Voc√™ √© um ASSISTENTE EDUCACIONAL especializado em NUTRI√á√ÉO ESPORTIVA. Seu objetivo √© auxiliar estudantes a compreender conceitos de nutri√ß√£o aplicada ao esporte, metabolismo energ√©tico, suplementa√ß√£o e estrat√©gias alimentares. Siga estas diretrizes:

1. CONTEXTO DO CURSO:
   - Padr√£o DNA-only
   - Citar no formato DNA (p√°gina apenas com metadado real)
   - Nunca exibir caminhos de arquivos nem c√≥digos internos

2. ESTILO DE RESPOSTA:
   - Usar linguagem cient√≠fica mas did√°tica
   - Relacionar conceitos nutricionais com performance esportiva
   - Fornecer exemplos pr√°ticos de aplica√ß√£o nutricional
   - Explicar os mecanismos bioqu√≠micos quando relevante

3. CITA√á√ïES E FONTES:
   - Sempre indicar a origem no formato DNA e usar aspas para cita√ß√µes diretas
   - Se a pergunta n√£o puder ser respondida com os materiais dispon√≠veis, informar explicitamente e, se √∫til, adicionar "Informa√ß√£o complementar (fora do acervo)"

4. ESTRAT√âGIAS PEDAG√ìGICAS:
   - Conectar bioqu√≠mica nutricional com aplica√ß√µes pr√°ticas
   - Usar exemplos de diferentes modalidades esportivas
   - Incentivar an√°lise cr√≠tica de estrat√©gias nutricionais
   - Sugerir adequa√ß√µes nutricionais para diferentes objetivos

Use {context}, {chat_history} e {question} como vari√°veis no template.""",
            "model": "gpt-4o-mini",
            "temperature": 0.2,
            "chunkSize": 2200,
            "chunkOverlap": 150,
            "retrievalSearchType": "mmr",
            "embeddingModel": "text-embedding-ada-002"
        },
        "Anatomia Humana": {
            "name": "Assistente Educacional de Anatomia Humana",
            "description": "Especializado em anatomia sist√™mica, cinesiologia e biomec√¢nica do movimento humano",
            "prompt": """Voc√™ √© um ASSISTENTE EDUCACIONAL especializado em ANATOMIA HUMANA. Seu objetivo √© auxiliar estudantes a compreender a estrutura do corpo humano, cinesiologia e biomec√¢nica do movimento. Siga estas diretrizes:

1. CONTEXTO DO CURSO:
   - Padr√£o DNA-only
   - Citar no formato DNA (p√°gina apenas com metadado real)
   - Nunca exibir caminhos de arquivos nem c√≥digos internos

2. ESTILO DE RESPOSTA:
   - Usar terminologia anat√¥mica precisa e correta
   - Relacionar estrutura anat√¥mica com fun√ß√£o
   - Fornecer exemplos de movimentos e posi√ß√µes
   - Explicar a biomec√¢nica quando relevante

3. CITA√á√ïES E FONTES:
   - Sempre indicar a origem no formato DNA e usar aspas para cita√ß√µes diretas
   - Se a pergunta n√£o puder ser respondida com os materiais dispon√≠veis, informar explicitamente e, se √∫til, adicionar "Informa√ß√£o complementar (fora do acervo)"

4. ESTRAT√âGIAS PEDAG√ìGICAS:
   - Conectar anatomia com movimento e fun√ß√£o
   - Usar exemplos pr√°ticos de palpa√ß√£o e identifica√ß√£o
   - Incentivar an√°lise cr√≠tica de estruturas anat√¥micas
   - Sugerir exerc√≠cios de memoriza√ß√£o e identifica√ß√£o

Use {context}, {chat_history} e {question} como vari√°veis no template.""",
            "model": "gpt-4o-mini",
            "temperature": 0.1,
            "chunkSize": 2000,
            "chunkOverlap": 100,
            "retrievalSearchType": "mmr",
            "embeddingModel": "text-embedding-ada-002"
        }
    }


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifespan manager para inicializar e limpar recursos"""
    global rag_handler, chroma_persist_dir, materials_dir

    logger.info("üöÄ Iniciando servidor RAG...")

    # Configurar diret√≥rios (usar vari√°veis de ambiente se definidas; caso contr√°rio, relativos ao diret√≥rio deste arquivo)
    base_dir = Path(__file__).parent

    # üéØ CORRE√á√ÉO: CAMINHOS DIN√ÇMICOS para Render vs Local
    # Detectar se est√° rodando no Render ou localmente
    is_render = (
        os.getenv("RENDER") or
        os.getenv("RENDER_ENVIRONMENT") or
        "onrender.com" in str(base_dir).lower() or
        "app" in str(base_dir).lower() or
        "\\app\\" in str(base_dir) or
        "/app/" in str(base_dir)
    )

    if is_render:
        # üöÄ RENDER: app/data (sem .chromadb autom√°tico) e app/data/materials
        default_chroma = None  # N√£o criar .chromadb automaticamente
        default_materials = base_dir / "data" / "materials"
        logger.info("üåê Ambiente detectado: RENDER")
    else:
        # üíª LOCAL: backend/data/.chromadb e backend/data/materials
        default_chroma = base_dir / "data" / ".chromadb"
        default_materials = base_dir / "data" / "materials"
        logger.info("üíª Ambiente detectado: LOCAL")

    # üö® CORRE√á√ÉO CR√çTICA: Garantir que os caminhos sejam absolutos e corretos
    logger.info(f"üîç Caminhos base:")
    logger.info(f"   - Base dir: {base_dir}")
    logger.info(f"   - Ambiente: {'RENDER' if is_render else 'LOCAL'}")
    logger.info(f"   - Default ChromaDB: {default_chroma}")
    logger.info(f"   - Default Materials: {default_materials}")
    logger.info(f"   - Base dir exists: {base_dir.exists()}")
    logger.info(f"   - Data dir exists: {(base_dir / 'data').exists()}")
    logger.info(f"   - ChromaDB dir exists: {default_chroma.exists()}")
    logger.info(f"   - Materials dir exists: {default_materials.exists()}")
    logger.info(f"   - ChromaDB path resolved: {default_chroma.resolve()}")
    logger.info(f"   - Materials path resolved: {default_materials.resolve()}")

    env_chroma = os.getenv("CHROMA_PERSIST_DIR")
    env_materials = os.getenv("MATERIALS_DIR")

    # üéØ CORRE√á√ÉO: N√£o criar .chromadb automaticamente no Render
    if env_chroma:
        chroma_persist_dir = Path(env_chroma)
    elif default_chroma:
        chroma_persist_dir = default_chroma
    else:
        chroma_persist_dir = None  # Render: deixar None at√© ser necess√°rio

    materials_dir = Path(env_materials) if env_materials else default_materials

    # Criar diret√≥rios se n√£o existirem (apenas estrutura b√°sica, sem .chromadb)
    materials_dir.mkdir(parents=True, exist_ok=True)
    Path("/app/logs").mkdir(parents=True, exist_ok=True)

    # üö® IMPORTANTE: N√ÉO criar .chromadb automaticamente
    if chroma_persist_dir and not str(chroma_persist_dir).endswith('.chromadb'):
        chroma_persist_dir.mkdir(parents=True, exist_ok=True)

    # üéØ VERIFICA√á√ÉO: Garantir que o caminho est√° correto
    logger.info(f"üîç Verificando caminhos:")
    logger.info(f"   - Base dir: {base_dir}")
    logger.info(f"   - ChromaDB path: {chroma_persist_dir}")
    if chroma_persist_dir:
        logger.info(f"   - ChromaDB exists: {chroma_persist_dir.exists()}")
        logger.info(f"   - ChromaDB is_dir: {chroma_persist_dir.is_dir()}")
    else:
        logger.info(
            f"   - ChromaDB: N√£o configurado (ser√° criado quando necess√°rio)")

    # Carregar configura√ß√µes do assistente
    load_assistant_configs()

    logger.info(f"üìÅ Diret√≥rios configurados:")
    logger.info(f"   - ChromaDB: {chroma_persist_dir}")
    logger.info(f"   - Materiais: {materials_dir}")

    # Verificar integridade do ChromaDB existente (se houver)
    if chroma_persist_dir:
        chromadb_status = check_chromadb_integrity(chroma_persist_dir)
        logger.info(f"üîç Status do ChromaDB: {chromadb_status['reason']}")

        if chromadb_status['valid']:
            logger.info(
                f"‚úÖ ChromaDB v√°lido encontrado com {chromadb_status['total_documents']} documentos")
            for col_info in chromadb_status['collections']:
                logger.info(
                    f"   - Cole√ß√£o '{col_info['name']}': {col_info['count']} documentos")
        else:
            logger.info(
                f"‚ÑπÔ∏è ChromaDB n√£o encontrado ou vazio: {chromadb_status['reason']}")
            logger.info(
                f"üí° Use a interface para fazer upload de um arquivo .chromadb existente")
    else:
        logger.info(
            f"‚ÑπÔ∏è ChromaDB n√£o configurado - ser√° criado quando necess√°rio")
        chromadb_status = {"valid": False,
                           "reason": "Not configured", "collections": []}

    # üéØ CORRE√á√ÉO: Inicializar RAG handler com NVIDIA_API_KEY (prioridade) ou OPENAI_API_KEY
    nvidia_api_key = os.getenv("NVIDIA_API_KEY")
    openai_api_key = os.getenv("OPENAI_API_KEY")

    # üö® IMPORTANTE: S√≥ inicializar RAG handler se chroma_persist_dir estiver configurado
    if not chroma_persist_dir:
        logger.info(
            "üí° ChromaDB n√£o configurado - RAG handler ser√° inicializado quando necess√°rio")
        logger.info("üí° Use a rota /initialize para configurar manualmente")
    else:
        if nvidia_api_key and nvidia_api_key != "your_nvidia_api_key_here":
            try:
                logger.info("üöÄ Inicializando RAG handler com NVIDIA API...")
                rag_handler = RAGHandler(
                    api_key=nvidia_api_key,
                    persist_dir=str(chroma_persist_dir),
                    materials_dir=str(materials_dir)
                )
                logger.info("‚úÖ RAG handler inicializado com NVIDIA API")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Falha ao inicializar com NVIDIA: {e}")
                # Fallback para OpenAI se NVIDIA falhar
                if openai_api_key and openai_api_key != "your_openai_api_key_here":
                    try:
                        logger.info(
                            "üîÑ Fallback: Inicializando RAG handler com OpenAI...")
                        rag_handler = RAGHandler(
                            api_key=openai_api_key,
                            persist_dir=str(chroma_persist_dir),
                            materials_dir=str(materials_dir)
                        )
                        logger.info(
                            "‚úÖ RAG handler inicializado com OpenAI (fallback)")
                    except Exception as e2:
                        logger.warning(f"‚ö†Ô∏è  Falha no fallback OpenAI: {e2}")
                else:
                    logger.info(
                        "üí° Use a rota /initialize para inicializar manualmente")
        elif openai_api_key and openai_api_key != "your_openai_api_key_here":
            try:
                logger.info("üîß Inicializando RAG handler com OpenAI API...")
                rag_handler = RAGHandler(
                    api_key=openai_api_key,
                    persist_dir=str(chroma_persist_dir),
                    materials_dir=str(materials_dir)
                )

                # Verificar se o RAG handler carregou dados existentes
                if rag_handler.vector_store:
                    try:
                        current_count = rag_handler.vector_store._collection.count()
                        if current_count > 0:
                            logger.info(
                                f"‚úÖ RAG handler carregou automaticamente {current_count} documentos do ChromaDB existente")
                            logger.info(
                                f"üìö Cole√ß√£o ativa: '{rag_handler.config.collection_name}'")
                        else:
                            logger.info(
                                "üìù RAG handler inicializado com ChromaDB vazio - pronto para receber novos materiais")
                    except Exception as e:
                        logger.warning(
                            f"‚ö†Ô∏è  N√£o foi poss√≠vel verificar contagem de documentos: {e}")

                logger.info("‚úÖ RAG handler inicializado com OpenAI")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Falha ao inicializar com OpenAI: {e}")
                logger.info(
                    "üí° Use a rota /initialize para inicializar manualmente")
        else:
            logger.info(
                "üí° Nenhuma API key configurada. Use a rota /initialize para inicializar o RAG handler")

    logger.info("‚úÖ Servidor RAG iniciado com sucesso")

    yield

    logger.info("üõë Encerrando servidor RAG...")
    # Salvar configura√ß√µes do assistente ao encerrar
    save_assistant_configs()

# Inicializar FastAPI
app = FastAPI(
    title="DNA da For√ßa RAG Server",
    description="Servidor RAG para processamento de materiais e treinamento de modelos",
    version="1.0.0",
    lifespan=lifespan
)

# Configurar CORS (permitir origem do frontend no Render e locais; tamb√©m suportar regex e env var)
cors_origins_env = os.getenv(
    "CORS_ORIGINS",
    "https://dna-forca-frontend.onrender.com,http://localhost:3000,http://127.0.0.1:3000",
)
cors_origins = [o.strip() for o in cors_origins_env.split(",") if o.strip()]
cors_origin_regex = os.getenv(
    "CORS_ORIGIN_REGEX", r"https://.*\\.onrender\\.com$")

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_origin_regex=cors_origin_regex,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(educational_agent_router, prefix="/chat")


# Banner de funcionamento ao iniciar (semelhante ao api_server.py)
@app.on_event("startup")
async def startup_banner():
    try:
        port = int(os.getenv("PORT", "8001"))
    except Exception:
        port = 8001
    logger.info("====================================================")
    logger.info(
        f"üöÄ DNA da For√ßa RAG Server v1.0.0 funcionando na porta {port}")
    logger.info("Rotas: GET /health | GET /status | POST /process-materials | POST /reprocess-enhanced-materials | POST /query | /chat/*")
    logger.info("====================================================")


def _apply_config_to_rag_handler(cfg: Dict[str, Any]):
    """Atualiza o RAGHandler com a configura√ß√£o recebida do frontend, se estiver inicializado."""
    global rag_handler
    if not rag_handler:
        return
    try:
        # Mapear campos do frontend para o RAGConfig
        if 'chunkSize' in cfg and isinstance(cfg['chunkSize'], int):
            rag_handler.config.chunk_size = cfg['chunkSize']
        if 'chunkOverlap' in cfg and isinstance(cfg['chunkOverlap'], int):
            rag_handler.config.chunk_overlap = cfg['chunkOverlap']
        if 'model' in cfg and isinstance(cfg['model'], str):
            rag_handler.config.model_name = cfg['model']
        if 'embeddingModel' in cfg and isinstance(cfg['embeddingModel'], str):
            rag_handler.config.embedding_model = cfg['embeddingModel']
            try:
                # Reinitialize embeddings and vector store to ensure new embedding model is used
                rag_handler._initialize_embeddings()
                rag_handler._initialize_vector_store()
            except Exception as reinit_err:
                logger.warning(
                    f"Falha ao reinicializar embeddings/vector store: {reinit_err}")
        if 'temperature' in cfg:
            try:
                rag_handler.config.temperature = float(cfg['temperature'])
            except Exception:
                pass
        if 'retrievalSearchType' in cfg and isinstance(cfg['retrievalSearchType'], str):
            rag_handler.config.retrieval_search_type = cfg['retrievalSearchType']
        # Reconfigurar retriever ap√≥s mudan√ßas
        rag_handler._setup_retriever()
    except Exception as e:
        logger.warning(
            f"N√£o foi poss√≠vel aplicar configura√ß√£o ao RAG handler: {e}")


def _get_effective_templates() -> Dict[str, Any]:
    """Retorna templates carregados ou os padr√µes se vazio."""
    global assistant_configs
    load_assistant_configs()
    if not assistant_configs:
        assistant_configs = get_default_templates()
    return assistant_configs


@app.get("/assistant/config")
async def get_assistant_config_rag():
    """Obter configura√ß√£o atual do assistente e templates dispon√≠veis."""
    global current_assistant_config
    load_assistant_configs()
    templates = _get_effective_templates()
    # Se n√£o h√° current, usar primeiro template dispon√≠vel
    if current_assistant_config is None and templates:
        first_name = next(iter(templates.keys()))
        current_assistant_config = templates[first_name]
    return {
        "status": "success",
        "config": current_assistant_config or {},
        "templates": templates,
    }


@app.post("/assistant/config")
async def update_assistant_config_rag(request: Request):
    """Atualizar configura√ß√£o do assistente (merge simples) e aplicar no RAG se poss√≠vel."""
    global current_assistant_config
    payload = await request.json()
    load_assistant_configs()
    if current_assistant_config is None:
        current_assistant_config = {}
    try:
        # Merge raso
        current_assistant_config.update(payload or {})
        _apply_config_to_rag_handler(current_assistant_config)
        save_assistant_configs()
        return {"status": "success", "config": current_assistant_config}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/assistant/templates")
async def get_assistant_templates_rag():
    """Listar templates dispon√≠veis (persistidos + padr√£o)."""
    templates = _get_effective_templates()
    return {"status": "success", "templates": templates}


@app.post("/assistant/config/template/{template_name}")
async def apply_assistant_template_rag(template_name: str):
    """Aplicar um template existente como configura√ß√£o atual e refletir no RAG."""
    global current_assistant_config
    templates = _get_effective_templates()
    if template_name not in templates:
        raise HTTPException(status_code=404, detail="Template not found")
    current_assistant_config = templates[template_name]
    _apply_config_to_rag_handler(current_assistant_config)
    save_assistant_configs()
    return {"status": "success", "config": current_assistant_config}


@app.post("/assistant/config/save-template")
async def save_assistant_template_rag(template_name: str, request: Request):
    """Salvar/atualizar um template com o corpo enviado."""
    global assistant_configs
    payload = await request.json()
    load_assistant_configs()
    assistant_configs[template_name] = payload or {}
    save_assistant_configs()
    return {"status": "success", "config": assistant_configs.get(template_name, {})}


@app.get("/health")
async def health_check():
    """Verificar sa√∫de do servidor RAG"""
    return {
        "status": "healthy",
        "service": "rag-server",
        "version": "1.0.0",
        "rag_initialized": rag_handler is not None
    }


@app.get("/status")
async def get_status():
    """Obter status detalhado do servidor RAG"""
    global rag_handler

    status = {
        "service": "rag-server",
        "version": "1.0.0",
        "rag_initialized": rag_handler is not None,
        "materials_directory": str(materials_dir) if materials_dir else None,
        "chroma_persist_dir": str(chroma_persist_dir) if chroma_persist_dir else None,
        "materials_count": 0,
        "vector_store_ready": False
    }

    if rag_handler:
        try:
            stats = rag_handler.get_system_stats()
            status.update(stats)
        except Exception as e:
            logger.error(f"Erro ao obter estat√≠sticas: {e}")

    return status


@app.post("/process-materials", response_model=ProcessResponse)
async def process_materials(request: ProcessMaterialsRequest, background_tasks: BackgroundTasks):
    """Process materials in the background with configurable educational features."""
    global rag_handler
    if not rag_handler:
        raise HTTPException(
            status_code=503, detail="RAG handler not initialized.")

    try:
        logger.info(
            f"üîÑ Starting material processing with educational features: {request.enable_educational_features}")

        # Update the handler's config for this task
        rag_handler.config.enable_educational_features = request.enable_educational_features

        background_tasks.add_task(
            rag_handler.process_documents, force_reprocess=request.force_reprocess)

        return ProcessResponse(
            success=True,
            message="Material processing started in the background."
        )
    except Exception as e:
        logger.error(f"‚ùå Error starting processing: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/reprocess-enhanced-materials", response_model=ProcessResponse)
async def reprocess_enhanced_materials(background_tasks: BackgroundTasks):
    """
    Reprocess all materials using the enhanced RAG system.

    This endpoint forces reprocessing of all documents with educational features enabled,
    such as extracting key concepts, assessing difficulty, and creating summaries.
    """
    global rag_handler
    if not rag_handler:
        raise HTTPException(
            status_code=503, detail="RAG handler not initialized.")

    try:
        logger.info("üöÄ Starting enhanced material reprocessing...")

        # For√ßar a ativa√ß√£o de recursos educacionais para este processo
        rag_handler.config.enable_educational_features = True

        # Adicionar a tarefa de reprocessamento em segundo plano
        background_tasks.add_task(
            rag_handler.process_documents, force_reprocess=True)

        return ProcessResponse(
            success=True,
            message="Enhanced material reprocessing started in the background."
        )
    except Exception as e:
        logger.error(f"‚ùå Error starting enhanced reprocessing: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ========================================
# MATERIALS MANAGEMENT (RAG-SIDE)
# ========================================

@app.get("/materials/list")
async def list_rag_materials():
    """Listar materiais que o servidor RAG enxerga (debug)."""
    try:
        root = Path(materials_dir)
        root.mkdir(parents=True, exist_ok=True)
        files = []
        for p in root.rglob("*"):
            if p.is_file():
                files.append(str(p.relative_to(root)))
        return {
            "root": str(root),
            "count": len(files),
            "files": files[:200],
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/materials/upload-archive")
async def upload_materials_archive_rag(
    archive: UploadFile = File(...),
    destination_subdir: Optional[str] = Form(None),
):
    """Enviar um .zip ou .tar.gz com materiais diretamente para o RAG e extrair em MATERIALS_DIR."""
    try:
        root = Path(materials_dir)
        root.mkdir(parents=True, exist_ok=True)

        # Salvar temporariamente
        tmp_dir = Path(tempfile.mkdtemp())
        tmp_path = tmp_dir / archive.filename
        content = await archive.read()
        if len(content) == 0:
            raise HTTPException(status_code=400, detail="Empty archive")
        tmp_path.write_bytes(content)

        # Destino final
        dest_dir = root / destination_subdir if destination_subdir else root
        dest_dir.mkdir(parents=True, exist_ok=True)

        # Extrair
        name_lower = archive.filename.lower()
        extracted_files = []
        if name_lower.endswith(".zip"):
            with zipfile.ZipFile(tmp_path, 'r') as zf:
                zf.extractall(dest_dir)
                extracted_files = zf.namelist()
        elif name_lower.endswith(".tar.gz") or name_lower.endswith(".tgz"):
            with tarfile.open(tmp_path, 'r:gz') as tf:
                tf.extractall(dest_dir)
                extracted_files = [
                    m.name for m in tf.getmembers() if m.isfile()]
        else:
            raise HTTPException(
                status_code=400, detail="Unsupported archive format. Use .zip or .tar.gz")

        # Limpeza
        try:
            tmp_path.unlink(missing_ok=True)  # type: ignore
            tmp_dir.rmdir()
        except Exception:
            pass

        return {
            "status": "success",
            "message": "Archive extracted to RAG materials",
            "destination": str(dest_dir),
            "files_count": len(extracted_files),
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/materials/sync-from-api")
async def sync_materials_from_api(api_base_url: str = Form(...), token: Optional[str] = Form(None)):
    """Baixa materials.tar.gz do API e extrai em MATERIALS_DIR (server-to-server)."""
    try:
        root = Path(materials_dir)
        root.mkdir(parents=True, exist_ok=True)

        archive_url = f"{api_base_url.rstrip('/')}/materials/archive"
        headers = {}
        if token:
            headers["Authorization"] = f"Bearer {token}"

        async with aiohttp.ClientSession() as session:
            async with session.get(archive_url, headers=headers) as resp:
                if resp.status != 200:
                    text = await resp.text()
                    raise HTTPException(
                        status_code=resp.status, detail=f"API error: {text}")
                content = await resp.read()

        # Salvar tempor√°rio e extrair
        tmp_dir = Path(tempfile.mkdtemp())
        tmp_path = tmp_dir / "materials.tar.gz"
        tmp_path.write_bytes(content)

        with tarfile.open(tmp_path, 'r:gz') as tf:
            tf.extractall(root)

        try:
            tmp_path.unlink(missing_ok=True)  # type: ignore
            tmp_dir.rmdir()
        except Exception:
            pass

        return {"status": "success", "message": "Materials synced from API"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/query", response_model=QueryResponse)
async def query_rag(request: QueryRequest):
    """Realizar consulta RAG"""
    global rag_handler

    if not rag_handler:
        raise HTTPException(
            status_code=503, detail="RAG handler n√£o inicializado")

    try:
        start_time = asyncio.get_event_loop().time()

        # Realizar consulta
        result = rag_handler.generate_response(
            question=request.question,
            user_level=request.user_level
        )

        end_time = asyncio.get_event_loop().time()
        response_time = end_time - start_time

        return QueryResponse(
            answer=result.get("answer", ""),
            sources=result.get("sources", []),
            response_time=response_time
        )

    except Exception as e:
        logger.error(f"‚ùå Erro na consulta RAG: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro na consulta: {str(e)}")


@app.post("/initialize")
async def initialize_rag(api_key: str):
    """Inicializar RAG handler"""
    global rag_handler

    try:
        logger.info("üîß Inicializando RAG handler...")

        rag_handler = RAGHandler(
            api_key=api_key,
            persist_dir=str(chroma_persist_dir)
        )

        logger.info("‚úÖ RAG handler inicializado com sucesso")
        return {"success": True, "message": "RAG handler inicializado"}

    except Exception as e:
        logger.error(f"‚ùå Erro ao inicializar RAG: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro na inicializa√ß√£o: {str(e)}")


@app.post("/reset")
async def reset_rag():
    """Resetar RAG handler"""
    global rag_handler

    try:
        if rag_handler:
            rag_handler.reset()
            logger.info("üîÑ RAG handler resetado")

        return {"success": True, "message": "RAG handler resetado"}

    except Exception as e:
        logger.error(f"‚ùå Erro ao resetar RAG: {e}")
        raise HTTPException(status_code=500, detail=f"Erro no reset: {str(e)}")


@app.get("/stats")
async def get_rag_stats():
    """Obter estat√≠sticas do RAG"""
    global rag_handler

    if not rag_handler:
        raise HTTPException(
            status_code=503, detail="RAG handler n√£o inicializado")

    try:
        stats = rag_handler.get_system_stats()
        return stats

    except Exception as e:
        logger.error(f"‚ùå Erro ao obter estat√≠sticas: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao obter estat√≠sticas: {str(e)}")


# ========================================
# CHAT ENDPOINTS
# ========================================

@app.post("/chat", response_model=Response)
async def chat(question: Question):
    """Simplified chat endpoint"""
    logger.info(f"üí¨ Chat request: {question.content[:50]}...")

    if not rag_handler:
        simulated_answer = f"Sistema n√£o inicializado. Esta √© uma resposta simulada para: '{question.content}'. Configure uma chave OpenAI v√°lida para funcionalidades completas."
        return Response(
            answer=simulated_answer,
            sources=[{"title": "Sistema de Teste",
                      "source": "rag_server.py", "page": 1, "relevance": 0.9}],
            response_time=0.1
        )

    try:
        response = rag_handler.generate_response(question.content)
        return response
    except Exception as e:
        logger.error(f"‚ùå Chat error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/chromadb/upload")
async def upload_chromadb_archive(
    archive: UploadFile = File(...),
    replace_existing: bool = Form(True)
):
    """Upload e substitui√ß√£o do banco ChromaDB treinado."""
    global rag_handler

    try:
        # Verificar se o arquivo √© um .tar.gz v√°lido
        if not archive.filename.lower().endswith(('.tar.gz', '.tgz')):
            raise HTTPException(
                status_code=400,
                detail="Arquivo deve ser .tar.gz contendo o diret√≥rio .chromadb"
            )

        # Ler o conte√∫do do arquivo
        content = await archive.read()
        if len(content) == 0:
            raise HTTPException(status_code=400, detail="Arquivo vazio")

        # Backup do ChromaDB atual se existir
        chroma_path = Path(chroma_persist_dir)
        backup_path = None

        if chroma_path.exists() and replace_existing:
            backup_path = chroma_path.parent / \
                f".chromadb_backup_{int(time.time())}"
            logger.info(
                f"üì¶ Fazendo backup do ChromaDB atual para {backup_path}")
            import shutil
            shutil.move(str(chroma_path), str(backup_path))

        # Criar diret√≥rio tempor√°rio para extra√ß√£o
        tmp_dir = Path(tempfile.mkdtemp())
        tmp_archive = tmp_dir / archive.filename
        tmp_archive.write_bytes(content)

        # Extrair o arquivo
        logger.info(f"üìÇ Extraindo ChromaDB para {chroma_path}")
        chroma_path.mkdir(parents=True, exist_ok=True)

        with tarfile.open(tmp_archive, 'r:gz') as tf:
            tf.extractall(chroma_path)

        # Limpeza do arquivo tempor√°rio
        try:
            tmp_archive.unlink(missing_ok=True)
            tmp_dir.rmdir()
        except Exception:
            pass

        # Verificar integridade do ChromaDB carregado
        integrity_check = check_chromadb_integrity(chroma_path)

        if not integrity_check["is_valid"]:
            # Restaurar backup se a verifica√ß√£o falhar
            if backup_path and backup_path.exists():
                logger.error(f"‚ùå ChromaDB inv√°lido, restaurando backup")
                if chroma_path.exists():
                    import shutil
                    shutil.rmtree(chroma_path)
                shutil.move(str(backup_path), str(chroma_path))

            raise HTTPException(
                status_code=400,
                detail=f"ChromaDB inv√°lido: {integrity_check['reason']}"
            )

        # Reinicializar o RAG handler se estiver ativo
        if rag_handler:
            logger.info("üîÑ Reinicializando RAG handler com novo ChromaDB")
            try:
                old_api_key = rag_handler.config.api_key
                rag_handler = RAGHandler(
                    api_key=old_api_key,
                    persist_dir=str(chroma_path)
                )
                logger.info("‚úÖ RAG handler reinicializado com sucesso")
            except Exception as e:
                logger.error(f"‚ùå Erro ao reinicializar RAG handler: {e}")

        # Remover backup se tudo deu certo
        if backup_path and backup_path.exists():
            import shutil
            shutil.rmtree(backup_path)
            logger.info("üóëÔ∏è Backup removido ap√≥s sucesso")

        return {
            "status": "success",
            "message": "ChromaDB carregado com sucesso",
            "collections": integrity_check.get("collections", []),
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro no upload do ChromaDB: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/chromadb/download")
async def download_chromadb_archive():
    """Download do banco ChromaDB completo em formato .tar.gz"""
    global chroma_persist_dir

    try:
        chroma_path = Path(chroma_persist_dir)

        if not chroma_path.exists():
            raise HTTPException(
                status_code=404,
                detail="Diret√≥rio ChromaDB n√£o encontrado"
            )

        # Verificar se h√° dados no ChromaDB
        try:
            client = chromadb.PersistentClient(path=str(chroma_path))
            collections = client.list_collections()

            if not collections:
                raise HTTPException(
                    status_code=404,
                    detail="ChromaDB est√° vazio - n√£o h√° dados para baixar"
                )

            total_documents = sum(col.count() for col in collections)
            logger.info(
                f"üìä ChromaDB cont√©m {len(collections)} cole√ß√µes com {total_documents} documentos")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao verificar ChromaDB: {e}")
            # Continuar mesmo com erro de verifica√ß√£o

        # Criar arquivo tempor√°rio para o tar.gz
        import tempfile
        import shutil

        with tempfile.NamedTemporaryFile(suffix='.tar.gz', delete=False) as tmp_file:
            tmp_path = Path(tmp_file.name)

        try:
            # Criar o arquivo tar.gz
            logger.info(
                f"üì¶ Criando arquivo .tar.gz do ChromaDB: {chroma_path}")

            with tarfile.open(tmp_path, 'w:gz') as tar:
                tar.add(chroma_path, arcname='.chromadb')

            # Verificar tamanho do arquivo
            file_size = tmp_path.stat().st_size
            logger.info(
                f"‚úÖ Arquivo .tar.gz criado: {file_size / (1024*1024):.2f} MB")

            # Retornar o arquivo para download
            def generate_file():
                try:
                    with open(tmp_path, 'rb') as f:
                        while chunk := f.read(8192):
                            yield chunk
                finally:
                    # Limpar arquivo tempor√°rio ap√≥s download
                    try:
                        tmp_path.unlink(missing_ok=True)
                    except Exception:
                        pass

            filename = f"chromadb_complete_{int(time.time())}.tar.gz"

            return StreamingResponse(
                generate_file(),
                media_type="application/gzip",
                headers={
                    "Content-Disposition": f"attachment; filename={filename}"
                }
            )

        except Exception as e:
            # Limpar arquivo tempor√°rio em caso de erro
            try:
                tmp_path.unlink(missing_ok=True)
            except Exception:
                pass
            raise e

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro ao criar download do ChromaDB: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno ao criar arquivo de download: {str(e)}"
        )


@app.post("/chromadb/compress")
async def compress_chromadb_folder():
    """Compactar pasta .chromadb n√£o compactada em arquivo .tar.gz"""
    global chroma_persist_dir

    try:
        logger.info("üì¶ Iniciando compress√£o do ChromaDB...")

        if not chroma_persist_dir:
            raise HTTPException(
                status_code=500,
                detail="ChromaDB persist directory n√£o configurado"
            )

        chroma_path = Path(chroma_persist_dir)
        logger.info(f"üîç Caminho do ChromaDB: {chroma_path}")

        if not chroma_path.exists():
            logger.error(f"‚ùå Diret√≥rio ChromaDB n√£o encontrado: {chroma_path}")
            raise HTTPException(
                status_code=404,
                detail=f"Diret√≥rio ChromaDB n√£o encontrado: {chroma_path}"
            )

        # Verificar se j√° existe arquivo compactado
        parent_dir = chroma_path.parent
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_name = f"chromadb_backup_{timestamp}.tar.gz"
        archive_path = parent_dir / archive_name

        logger.info(f"üìÅ Pasta pai: {parent_dir}")
        logger.info(f"üì¶ Arquivo ser√° salvo em: {archive_path}")

        if archive_path.exists():
            logger.warning(f"‚ö†Ô∏è Arquivo j√° existe, removendo: {archive_path}")
            archive_path.unlink()

        # Criar arquivo tar.gz na pasta do ChromaDB
        logger.info("üîß Criando arquivo tar.gz...")
        with tarfile.open(archive_path, "w:gz") as tar:
            tar.add(chroma_path, arcname=chroma_path.name)

        file_size = archive_path.stat().st_size
        logger.info(f"‚úÖ Arquivo criado com sucesso: {archive_path}")
        logger.info(
            f"üìè Tamanho: {file_size:,} bytes ({file_size / (1024*1024):.2f} MB)")

        # Retornar informa√ß√µes do arquivo criado
        return {
            "status": "success",
            "message": "ChromaDB compactado com sucesso",
            "file_path": str(archive_path),
            "file_name": archive_name,
            "file_size": file_size,
            "file_size_mb": round(file_size / (1024*1024), 2),
            "created_at": timestamp,
            "location": "local_folder"
        }

    except Exception as e:
        logger.error(f"‚ùå Erro durante compress√£o: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro durante compress√£o: {str(e)}"
        )


@app.post("/chromadb/compress-local")
async def compress_local_chromadb_folder(request: CompressLocalRequest):
    """Compactar pasta .chromadb local em arquivo .tar.gz"""
    try:
        # Extrair par√¢metros da requisi√ß√£o
        source_path = request.source_path
        output_filename = request.output_filename or f"chromadb_local_{int(time.time())}.tar.gz"

        logger.info(f"üì¶ Compactando pasta local: {source_path}")

        # Resolver o caminho da pasta .chromadb local
        # Se for caminho relativo, tentar diferentes localiza√ß√µes
        local_chroma_path = None

        # Tentar diferentes caminhos poss√≠veis
        possible_paths = [
            Path(source_path),  # Caminho exato fornecido
            Path.cwd() / source_path,  # Caminho relativo ao diret√≥rio atual
            Path.cwd().parent / source_path,  # Um n√≠vel acima
            Path.cwd().parent.parent / source_path,  # Dois n√≠veis acima
        ]

        for path in possible_paths:
            if path.exists() and path.is_dir():
                local_chroma_path = path
                logger.info(
                    f"‚úÖ Pasta .chromadb encontrada em: {local_chroma_path.absolute()}")
                break

        if not local_chroma_path:
            # Listar diret√≥rios dispon√≠veis para debug
            current_dir = Path.cwd()
            logger.error(
                f"‚ùå Pasta .chromadb n√£o encontrada. Diret√≥rio atual: {current_dir}")
            logger.error(f"‚ùå Tentou os seguintes caminhos:")
            for path in possible_paths:
                logger.error(
                    f"   - {path.absolute()} (existe: {path.exists()}, √©_dir: {path.is_dir() if path.exists() else 'N/A'})")

            raise HTTPException(
                status_code=404,
                detail=f"Pasta .chromadb n√£o encontrada. Verifique se est√° no diret√≥rio correto."
            )

        # Verificar se h√° dados na pasta local
        try:
            # Tentar conectar ao ChromaDB local para verificar integridade
            client = chromadb.PersistentClient(path=str(local_chroma_path))
            collections = client.list_collections()

            if not collections:
                raise HTTPException(
                    status_code=404,
                    detail="Pasta local est√° vazia - n√£o h√° dados para compactar"
                )

            total_documents = sum(col.count() for col in collections)
            logger.info(
                f"üìä Pasta local cont√©m {len(collections)} cole√ß√µes com {total_documents} documentos")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao verificar pasta local: {e}")
            # Continuar mesmo com erro de verifica√ß√£o

        # Criar arquivo tempor√°rio para o tar.gz
        import tempfile
        import shutil

        with tempfile.NamedTemporaryFile(suffix='.tar.gz', delete=False) as tmp_file:
            tmp_path = Path(tmp_file.name)

        try:
            # Criar o arquivo tar.gz
            logger.info(
                f"üì¶ Compactando pasta local {source_path} em .tar.gz: {local_chroma_path}")

            with tarfile.open(tmp_path, 'w:gz') as tar:
                # Compactar a pasta inteira .chromadb
                tar.add(local_chroma_path, arcname='.chromadb')

            # Verificar tamanho do arquivo
            file_size = tmp_path.stat().st_size
            logger.info(
                f"‚úÖ Arquivo .tar.gz criado: {file_size / (1024*1024):.2f} MB")

            # Retornar o arquivo para download
            def generate_file():
                try:
                    with open(tmp_path, 'rb') as f:
                        while chunk := f.read(8192):
                            yield chunk
                finally:
                    # Limpar arquivo tempor√°rio ap√≥s download
                    try:
                        tmp_path.unlink(missing_ok=True)
                    except Exception:
                        pass

            return StreamingResponse(
                generate_file(),
                media_type="application/gzip",
                headers={
                    "Content-Disposition": f"attachment; filename={output_filename}"
                }
            )

        except Exception as e:
            # Limpar arquivo tempor√°rio em caso de erro
            try:
                tmp_path.unlink(missing_ok=True)
            except Exception:
                pass
            raise e

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro ao compactar pasta local: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno ao compactar pasta local: {str(e)}"
        )


@app.post("/chromadb/compress-local-path")
async def compress_local_chromadb_folder_by_path(request: CompressLocalRequest):
    """Compactar pasta .chromadb local especificando caminho completo"""
    try:
        # Extrair par√¢metros da requisi√ß√£o
        source_path = request.source_path
        output_filename = request.output_filename or f"chromadb_local_{int(time.time())}.tar.gz"

        logger.info(f"üì¶ Compactando pasta local por caminho: {source_path}")

        # Usar o caminho exato fornecido
        local_chroma_path = Path(source_path)

        if not local_chroma_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f"Pasta n√£o encontrada: {source_path}"
            )

        if not local_chroma_path.is_dir():
            raise HTTPException(
                status_code=400,
                detail=f"Caminho n√£o √© uma pasta v√°lida: {source_path}"
            )

        # Verificar se √© realmente uma pasta .chromadb
        if not local_chroma_path.name == ".chromadb":
            logger.warning(
                f"‚ö†Ô∏è Pasta n√£o se chama '.chromadb': {local_chroma_path.name}")

        # Verificar se h√° dados na pasta local
        try:
            # Tentar conectar ao ChromaDB local para verificar integridade
            client = chromadb.PersistentClient(path=str(local_chroma_path))
            collections = client.list_collections()

            if not collections:
                raise HTTPException(
                    status_code=404,
                    detail="Pasta local est√° vazia - n√£o h√° dados para compactar"
                )

            total_documents = sum(col.count() for col in collections)
            logger.info(
                f"üìä Pasta local cont√©m {len(collections)} cole√ß√µes com {total_documents} documentos")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao verificar pasta local: {e}")
            # Continuar mesmo com erro de verifica√ß√£o

        # Criar arquivo tempor√°rio para o tar.gz
        import tempfile
        import shutil

        with tempfile.NamedTemporaryFile(suffix='.tar.gz', delete=False) as tmp_file:
            tmp_path = Path(tmp_file.name)

        try:
            # Criar o arquivo tar.gz
            logger.info(
                f"üì¶ Compactando pasta local {source_path} em .tar.gz: {local_chroma_path}")

            with tarfile.open(tmp_path, 'w:gz') as tar:
                # Compactar a pasta inteira .chromadb
                tar.add(local_chroma_path, arcname='.chromadb')

            # Verificar tamanho do arquivo
            file_size = tmp_path.stat().st_size
            logger.info(
                f"‚úÖ Arquivo .tar.gz criado: {file_size / (1024*1024):.2f} MB")

            # Retornar o arquivo para download
            def generate_file():
                try:
                    with open(tmp_path, 'rb') as f:
                        while chunk := f.read(8192):
                            yield chunk
                finally:
                    # Limpar arquivo tempor√°rio ap√≥s download
                    try:
                        tmp_path.unlink(missing_ok=True)
                    except Exception:
                        pass

            return StreamingResponse(
                generate_file(),
                media_type="application/gzip",
                headers={
                    "Content-Disposition": f"attachment; filename={output_filename}"
                }
            )

        except Exception as e:
            # Limpar arquivo tempor√°rio em caso de erro
            try:
                tmp_path.unlink(missing_ok=True)
            except Exception:
                pass
            raise e

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro ao compactar pasta local por caminho: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro interno ao compactar pasta local: {str(e)}"
        )


@app.post("/chromadb/upload-folder")
async def upload_chromadb_folder(
    folder: UploadFile = File(...),
    replace_existing: bool = Form(True)
):
    """Upload de pasta .chromadb n√£o compactada (zipada)"""
    global rag_handler

    try:
        # Verificar se √© um arquivo zip v√°lido
        if not folder.filename.lower().endswith('.zip'):
            raise HTTPException(
                status_code=400,
                detail="Arquivo deve ser .zip contendo o diret√≥rio .chromadb"
            )

        # Ler o conte√∫do do arquivo
        content = await folder.read()
        if len(content) == 0:
            raise HTTPException(status_code=400, detail="Arquivo vazio")

        # Backup do ChromaDB atual se existir
        chroma_path = Path(chroma_persist_dir)
        backup_path = None

        if chroma_path.exists() and replace_existing:
            backup_path = chroma_path.parent / \
                f".chromadb_backup_{int(time.time())}"
            logger.info(
                f"üì¶ Fazendo backup do ChromaDB atual para {backup_path}")
            import shutil
            shutil.move(str(chroma_path), str(backup_path))

        # Criar diret√≥rio tempor√°rio para extra√ß√£o
        tmp_dir = Path(tempfile.mkdtemp())
        tmp_archive = tmp_dir / folder.filename
        tmp_archive.write_bytes(content)

        # Extrair o arquivo zip
        logger.info(f"üìÇ Extraindo pasta .chromadb do zip para {chroma_path}")
        chroma_path.mkdir(parents=True, exist_ok=True)

        with zipfile.ZipFile(tmp_archive, 'r') as zf:
            zf.extractall(chroma_path)

        # Limpeza do arquivo tempor√°rio
        try:
            tmp_archive.unlink(missing_ok=True)
            tmp_dir.rmdir()
        except Exception:
            pass

        # Verificar integridade do ChromaDB carregado
        integrity_check = check_chromadb_integrity(chroma_path)

        if not integrity_check["is_valid"]:
            # Restaurar backup se a verifica√ß√£o falhar
            if backup_path and backup_path.exists():
                logger.error(f"‚ùå ChromaDB inv√°lido, restaurando backup")
                if chroma_path.exists():
                    import shutil
                    shutil.rmtree(chroma_path)
                shutil.move(str(backup_path), str(chroma_path))

            raise HTTPException(
                status_code=400,
                detail=f"ChromaDB inv√°lido: {integrity_check['reason']}"
            )

        # Reinicializar o RAG handler se estiver ativo
        if rag_handler:
            logger.info("üîÑ Reinicializando RAG handler com novo ChromaDB")
            try:
                old_api_key = rag_handler.config.api_key
                rag_handler = RAGHandler(
                    api_key=old_api_key,
                    persist_dir=str(chroma_path)
                )
                logger.info("‚úÖ RAG handler reinicializado com sucesso")
            except Exception as e:
                logger.error(f"‚ùå Erro ao reinicializar RAG handler: {e}")

        # Remover backup se tudo deu certo
        if backup_path and backup_path.exists():
            import shutil
            shutil.rmtree(backup_path)
            logger.info("üóëÔ∏è Backup removido ap√≥s sucesso")

        return {
            "status": "success",
            "message": "Pasta .chromadb carregada com sucesso",
            "collections": integrity_check.get("collections", []),
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro no upload da pasta .chromadb: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/debug/system")
async def debug_system():
    """Debug detalhado do sistema para troubleshooting"""
    try:
        # Verificar vari√°veis de ambiente
        env_vars = {
            "RENDER": os.getenv("RENDER"),
            "RENDER_ENVIRONMENT": os.getenv("RENDER_ENVIRONMENT"),
            "CHROMA_PERSIST_DIR": os.getenv("CHROMA_PERSIST_DIR"),
            "MATERIALS_DIR": os.getenv("MATERIALS_DIR"),
            "PORT": os.getenv("PORT"),
            "CORS_ORIGINS": os.getenv("CORS_ORIGINS"),
            "NVIDIA_API_KEY": "***" if os.getenv("NVIDIA_API_KEY") else None,
            "OPENAI_API_KEY": "***" if os.getenv("OPENAI_API_KEY") else None,
            "GEMINI_API_KEY": "***" if os.getenv("GEMINI_API_KEY") else None,
        }

        # Verificar diret√≥rios
        dir_status = {}
        if chroma_persist_dir:
            dir_status["chroma_persist_dir"] = {
                "path": str(chroma_persist_dir),
                "exists": chroma_persist_dir.exists(),
                "is_dir": chroma_persist_dir.is_dir() if chroma_persist_dir.exists() else False,
                "size": sum(f.stat().st_size for f in chroma_persist_dir.rglob('*') if f.is_file()) if chroma_persist_dir.exists() else 0
            }

        if materials_dir:
            dir_status["materials_dir"] = {
                "path": str(materials_dir),
                "exists": materials_dir.exists(),
                "is_dir": materials_dir.is_dir() if materials_dir.exists() else False,
                "file_count": len(list(materials_dir.rglob('*'))) if materials_dir.exists() else 0
            }

        # Verificar RAG handler
        rag_status = {
            "initialized": rag_handler is not None,
            "vector_store_ready": rag_handler.vector_store is not None if rag_handler else False,
            "embeddings_ready": rag_handler.embeddings is not None if rag_handler else False,
            "llm_ready": rag_handler.llm is not None if rag_handler else False
        }

        if rag_handler:
            try:
                rag_status["vector_store_count"] = rag_handler.vector_store._collection.count(
                ) if rag_handler.vector_store else 0
            except Exception as e:
                rag_status["vector_store_count_error"] = str(e)

        return {
            "status": "success",
            "timestamp": time.time(),
            "environment_variables": env_vars,
            "directory_status": dir_status,
            "rag_handler_status": rag_status,
            "system_info": {
                "python_version": f"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}",
                "platform": os.sys.platform,
                "current_working_directory": str(Path.cwd()),
                "script_location": str(Path(__file__).parent)
            }
        }
    except Exception as e:
        logger.error(f"‚ùå Erro no debug do sistema: {e}")
        return {
            "status": "error",
            "message": str(e),
            "timestamp": time.time()
        }


@app.get("/test-connection")
async def test_connection():
    """Teste de conectividade e status b√°sico do servidor"""
    try:
        return {
            "status": "success",
            "message": "Servidor RAG funcionando",
            "timestamp": time.time(),
            "chroma_persist_dir": str(chroma_persist_dir) if chroma_persist_dir else None,
            "materials_dir": str(materials_dir) if materials_dir else None,
            "rag_handler_active": rag_handler is not None,
            "environment": "RENDER" if os.getenv("RENDER") else "LOCAL"
        }
    except Exception as e:
        logger.error(f"‚ùå Erro no teste de conex√£o: {e}")
        return {
            "status": "error",
            "message": str(e),
            "timestamp": time.time()
        }


@app.get("/chromadb/status")
async def get_chromadb_status():
    """Verificar status e integridade do ChromaDB atual."""
    try:
        chroma_path = Path(chroma_persist_dir)

        if not chroma_path.exists():
            return {
                "status": "not_found",
                "message": "ChromaDB n√£o encontrado",
                "path": str(chroma_path)
            }

        integrity_check = check_chromadb_integrity(chroma_path)

        return {
            "status": "found" if integrity_check["valid"] else "invalid",
            "path": str(chroma_path),
            "is_valid": integrity_check["valid"],
            "reason": integrity_check.get("reason"),
            "collections": integrity_check.get("collections", []),
            "total_documents": sum(c.get("count", 0) for c in integrity_check.get("collections", [])),
            "rag_handler_active": rag_handler is not None
        }

    except Exception as e:
        logger.error(f"‚ùå Erro ao verificar status do ChromaDB: {e}")
        return {
            "status": "error",
            "message": str(e)
        }


@app.post("/initialize")
async def initialize_rag(api_key: str):
    """Inicializar RAG handler"""
    global rag_handler

    try:
        logger.info("üîß Inicializando RAG handler...")

        rag_handler = RAGHandler(
            api_key=api_key,
            persist_dir=str(chroma_persist_dir)
        )

        logger.info("‚úÖ RAG handler inicializado com sucesso")
        return {"success": True, "message": "RAG handler inicializado"}

    except Exception as e:
        logger.error(f"‚ùå Erro ao inicializar RAG: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro na inicializa√ß√£o: {str(e)}")


@app.post("/reset")
async def reset_rag():
    """Resetar RAG handler"""
    global rag_handler

    try:
        if rag_handler:
            rag_handler.reset()
            logger.info("üîÑ RAG handler resetado")

        return {"success": True, "message": "RAG handler resetado"}

    except Exception as e:
        logger.error(f"‚ùå Erro ao resetar RAG: {e}")
        raise HTTPException(status_code=500, detail=f"Erro no reset: {str(e)}")


@app.get("/stats")
async def get_rag_stats():
    """Obter estat√≠sticas do RAG"""
    global rag_handler

    if not rag_handler:
        raise HTTPException(
            status_code=503, detail="RAG handler n√£o inicializado")

    try:
        stats = rag_handler.get_system_stats()
        return stats

    except Exception as e:
        logger.error(f"‚ùå Erro ao obter estat√≠sticas: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao obter estat√≠sticas: {str(e)}")


# ========================================
# CHAT ENDPOINTS
# ========================================

@app.post("/chat", response_model=Response)
async def chat(question: Question):
    """Simplified chat endpoint"""
    logger.info(f"üí¨ Chat request: {question.content[:50]}...")

    if not rag_handler:
        simulated_answer = f"Sistema n√£o inicializado. Esta √© uma resposta simulada para: '{question.content}'. Configure uma chave OpenAI v√°lida para funcionalidades completas."
        return Response(
            answer=simulated_answer,
            sources=[{"title": "Sistema de Teste",
                      "source": "rag_server.py", "page": 1, "relevance": 0.9}],
            response_time=0.1
        )

    try:
        response = rag_handler.generate_response(question.content)
        return response
    except Exception as e:
        logger.error(f"‚ùå Chat error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/chromadb/backups")
async def list_chromadb_backups():
    """Listar arquivos de backup do ChromaDB"""
    global chroma_persist_dir

    try:
        if not chroma_persist_dir:
            raise HTTPException(
                status_code=500,
                detail="ChromaDB persist directory n√£o configurado"
            )

        chroma_path = Path(chroma_persist_dir)
        parent_dir = chroma_path.parent

        # Buscar arquivos .tar.gz de backup
        backup_files = []
        for file_path in parent_dir.glob("chromadb_backup_*.tar.gz"):
            stat = file_path.stat()
            backup_files.append({
                "filename": file_path.name,
                "file_path": str(file_path),
                "size_bytes": stat.st_size,
                "size_mb": round(stat.st_size / (1024*1024), 2),
                "created_at": datetime.fromtimestamp(stat.st_ctime).strftime("%Y-%m-%d %H:%M:%S"),
                "modified_at": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S")
            })

        # Ordenar por data de cria√ß√£o (mais recente primeiro)
        backup_files.sort(key=lambda x: x["created_at"], reverse=True)

        return {
            "status": "success",
            "backup_dir": str(parent_dir),
            "total_backups": len(backup_files),
            "backups": backup_files
        }

    except Exception as e:
        logger.error(f"‚ùå Erro ao listar backups: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao listar backups: {str(e)}"
        )


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="DNA da For√ßa RAG Server")
    parser.add_argument("--host", default="0.0.0.0",
                        help="Host para o servidor")
    # Permitir que o Render defina a PORT
    default_port = int(os.getenv("PORT", "8001"))
    parser.add_argument("--port", type=int, default=default_port,
                        help="Porta para o servidor")
    parser.add_argument("--reload", action="store_true",
                        help="Habilitar reload autom√°tico")

    args = parser.parse_args()

    logger.info(f"üöÄ Iniciando servidor RAG em {args.host}:{args.port}...")
    uvicorn.run(
        "rag_server:app",
        host=args.host,
        port=args.port,
        reload=args.reload,
        log_level="info"
    )


def check_chromadb_integrity(persist_dir: Path) -> Dict[str, Any]:
    """Verificar integridade e conte√∫do do ChromaDB"""
    try:
        if not persist_dir.exists():
            return {"valid": False, "reason": "Directory does not exist", "collections": []}

        # Verificar se h√° arquivos do ChromaDB
        chromadb_files = list(persist_dir.rglob("*.sqlite*")) + \
            list(persist_dir.rglob("chroma.sqlite3"))
        if not chromadb_files:
            return {"valid": False, "reason": "No ChromaDB files found", "collections": []}

        # Tentar conectar e listar cole√ß√µes
        client = chromadb.PersistentClient(path=str(persist_dir))
        collections = client.list_collections()

        collections_info = []
        total_documents = 0

        for collection in collections:
            try:
                count = collection.count()
                collections_info.append({
                    "name": collection.name,
                    "count": count,
                    "metadata": getattr(collection, 'metadata', {})
                })
                total_documents += count
            except Exception as e:
                logger.warning(
                    f"Erro ao verificar cole√ß√£o {collection.name}: {e}")
                collections_info.append({
                    "name": collection.name,
                    "count": 0,
                    "error": str(e)
                })

        return {
            "valid": total_documents > 0,
            "reason": f"Found {len(collections)} collections with {total_documents} total documents",
            "collections": collections_info,
            "total_documents": total_documents
        }

    except Exception as e:
        return {"valid": False, "reason": f"Error checking ChromaDB: {str(e)}", "collections": []}
