#!/usr/bin/env python3
"""
Visualizador 3D do Banco de Dados Vetorial (ChromaDB)
Permite visualizar os embeddings dos documentos em 3D para an√°lise e debug.

Funcionalidades:
- Visualiza√ß√£o 3D com PCA, t-SNE e UMAP
- Clustering autom√°tico dos documentos
- Interatividade com plotly
- An√°lise de similaridade entre documentos
- Exporta√ß√£o de visualiza√ß√µes

Autor: Sistema RAG DNA da For√ßa
"""

import os
import sys
import logging
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import json
import time

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Adicionar o diret√≥rio raiz ao path para imports
sys.path.append(str(Path(__file__).parent))

try:
    import chromadb
    from chromadb.config import Settings
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.subplots import make_subplots
    import plotly.offline as pyo
    from sklearn.decomposition import PCA
    from sklearn.manifold import TSNE
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    import umap
    from collections import defaultdict
    import matplotlib.pyplot as plt
    import seaborn as sns
except ImportError as e:
    logger.error(f"‚ùå Depend√™ncias n√£o encontradas: {e}")
    logger.info("üí° Instale com: pip install plotly scikit-learn umap-learn matplotlib seaborn")
    sys.exit(1)

class VectorDBVisualizer:
    """Visualizador 3D do banco de dados vetorial"""
    
    def __init__(self, persist_dir: str = "data/.chromadb"):
        self.persist_dir = Path(persist_dir)
        self.client = None
        self.collections = {}
        self.embeddings = {}
        self.metadata = {}
        self.documents = {}
        
    def connect_to_chromadb(self) -> bool:
        """Conecta ao ChromaDB e carrega as cole√ß√µes"""
        try:
            if not self.persist_dir.exists():
                logger.error(f"‚ùå Diret√≥rio ChromaDB n√£o encontrado: {self.persist_dir}")
                return False
                
            # Conectar ao ChromaDB
            self.client = chromadb.PersistentClient(path=str(self.persist_dir))
            logger.info(f"‚úÖ Conectado ao ChromaDB em: {self.persist_dir}")
            
            # Listar cole√ß√µes
            collections = self.client.list_collections()
            logger.info(f"üìö Cole√ß√µes encontradas: {len(collections)}")
            
            for collection in collections:
                logger.info(f"   - {collection.name}: {collection.count()} documentos")
                
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao conectar ao ChromaDB: {e}")
            return False
    
    def load_collection_data(self, collection_name: str) -> bool:
        """Carrega dados de uma cole√ß√£o espec√≠fica"""
        try:
            collection = self.client.get_collection(collection_name)
            
            # Obter todos os documentos
            results = collection.get(
                include=['embeddings', 'documents', 'metadatas']
            )
            
            self.collections[collection_name] = collection
            self.embeddings[collection_name] = np.array(results['embeddings'])
            self.documents[collection_name] = results['documents']
            self.metadata[collection_name] = results['metadatas']
            
            logger.info(f"‚úÖ Cole√ß√£o '{collection_name}' carregada:")
            logger.info(f"   - Embeddings: {self.embeddings[collection_name].shape}")
            logger.info(f"   - Documentos: {len(self.documents[collection_name])}")
            logger.info(f"   - Metadados: {len(self.metadata[collection_name])}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar cole√ß√£o '{collection_name}': {e}")
            return False
    
    def reduce_dimensions(self, embeddings: np.ndarray, method: str = "pca", n_components: int = 3) -> np.ndarray:
        """Reduz dimensionalidade dos embeddings para visualiza√ß√£o"""
        try:
            logger.info(f"üîß Reduzindo dimensionalidade com {method.upper()}...")
            
            if method.lower() == "pca":
                reducer = PCA(n_components=n_components, random_state=42)
                reduced = reducer.fit_transform(embeddings)
                explained_variance = reducer.explained_variance_ratio_
                logger.info(f"‚úÖ PCA: Vari√¢ncia explicada: {explained_variance}")
                
            elif method.lower() == "tsne":
                reducer = TSNE(n_components=n_components, random_state=42, perplexity=min(30, len(embeddings)-1))
                reduced = reducer.fit_transform(embeddings)
                logger.info(f"‚úÖ t-SNE: Dimensionalidade reduzida para {n_components}D")
                
            elif method.lower() == "umap":
                reducer = umap.UMAP(n_components=n_components, random_state=42, n_neighbors=min(15, len(embeddings)-1))
                reduced = reducer.fit_transform(embeddings)
                logger.info(f"‚úÖ UMAP: Dimensionalidade reduzida para {n_components}D")
                
            else:
                raise ValueError(f"M√©todo n√£o suportado: {method}")
            
            return reduced
            
        except Exception as e:
            logger.error(f"‚ùå Erro na redu√ß√£o de dimensionalidade: {e}")
            return None
    
    def cluster_documents(self, embeddings: np.ndarray, n_clusters: int = 5) -> np.ndarray:
        """Aplica clustering K-means aos documentos"""
        try:
            logger.info(f"üéØ Aplicando clustering K-means com {n_clusters} clusters...")
            
            # Normalizar embeddings
            scaler = StandardScaler()
            embeddings_scaled = scaler.fit_transform(embeddings)
            
            # Aplicar K-means
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            clusters = kmeans.fit_predict(embeddings_scaled)
            
            logger.info(f"‚úÖ Clustering aplicado: {len(np.unique(clusters))} clusters")
            return clusters
            
        except Exception as e:
            logger.error(f"‚ùå Erro no clustering: {e}")
            return None
    
    def create_3d_scatter(self, collection_name: str, method: str = "pca", n_clusters: int = 5) -> go.Figure:
        """Cria visualiza√ß√£o 3D interativa dos embeddings"""
        try:
            embeddings = self.embeddings[collection_name]
            documents = self.documents[collection_name]
            metadata = self.metadata[collection_name]
            
            # Reduzir dimensionalidade
            reduced_embeddings = self.reduce_dimensions(embeddings, method)
            if reduced_embeddings is None:
                raise ValueError("Falha na redu√ß√£o de dimensionalidade")
            
            # Aplicar clustering
            clusters = self.cluster_documents(embeddings, n_clusters)
            if clusters is None:
                clusters = np.zeros(len(embeddings), dtype=int)
            
            # Criar DataFrame para plotagem
            df = pd.DataFrame({
                'x': reduced_embeddings[:, 0],
                'y': reduced_embeddings[:, 1],
                'z': reduced_embeddings[:, 2],
                'cluster': clusters,
                'document': [doc[:100] + "..." if len(doc) > 100 else doc for doc in documents],
                'source': [meta.get('source', 'N/A') if meta else 'N/A' for meta in metadata]
            })
            
            # Criar figura 3D
            fig = go.Figure()
            
            # Adicionar pontos por cluster
            colors = px.colors.qualitative.Set3
            for cluster_id in sorted(df['cluster'].unique()):
                cluster_data = df[df['cluster'] == cluster_id]
                
                fig.add_trace(go.Scatter3d(
                    x=cluster_data['x'],
                    y=cluster_data['y'],
                    z=cluster_data['z'],
                    mode='markers',
                    marker=dict(
                        size=8,
                        color=colors[cluster_id % len(colors)],
                        opacity=0.8
                    ),
                    text=cluster_data['document'],
                    hovertemplate='<b>Documento:</b> %{text}<br>' +
                                '<b>Fonte:</b> %{customdata}<br>' +
                                '<b>Cluster:</b> ' + str(cluster_id) + '<br>' +
                                '<b>Coordenadas:</b> (%{x:.2f}, %{y:.2f}, %{z:.2f})<extra></extra>',
                    customdata=cluster_data['source'],
                    name=f'Cluster {cluster_id}',
                    showlegend=True
                ))
            
            # Configurar layout
            fig.update_layout(
                title=f"Visualiza√ß√£o 3D - {collection_name} ({method.upper()})",
                scene=dict(
                    xaxis_title=f"{method.upper()} Componente 1",
                    yaxis_title=f"{method.upper()} Componente 2",
                    zaxis_title=f"{method.upper()} Componente 3",
                    camera=dict(
                        eye=dict(x=1.5, y=1.5, z=1.5)
                    )
                ),
                width=1000,
                height=800,
                showlegend=True
            )
            
            logger.info(f"‚úÖ Visualiza√ß√£o 3D criada para '{collection_name}'")
            return fig
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar visualiza√ß√£o 3D: {e}")
            return None
    
    def create_2d_visualizations(self, collection_name: str) -> go.Figure:
        """Cria visualiza√ß√µes 2D com diferentes m√©todos"""
        try:
            embeddings = self.embeddings[collection_name]
            documents = self.documents[collection_name]
            metadata = self.metadata[collection_name]
            
            # Reduzir dimensionalidade para 2D com diferentes m√©todos
            methods = ["pca", "tsne", "umap"]
            reduced_data = {}
            
            for method in methods:
                reduced = self.reduce_dimensions(embeddings, method, n_components=2)
                if reduced is not None:
                    reduced_data[method] = reduced
            
            # Criar subplots
            fig = make_subplots(
                rows=1, cols=len(reduced_data),
                subplot_titles=[f"{method.upper()}" for method in reduced_data.keys()],
                specs=[[{"type": "scatter"} for _ in reduced_data]]
            )
            
            # Adicionar pontos para cada m√©todo
            colors = px.colors.qualitative.Set3
            for i, (method, reduced) in enumerate(reduced_data.items()):
                fig.add_trace(
                    go.Scatter(
                        x=reduced[:, 0],
                        y=reduced[:, 1],
                        mode='markers',
                        marker=dict(
                            size=6,
                            color=colors[i % len(colors)],
                            opacity=0.7
                        ),
                        text=[doc[:50] + "..." if len(doc) > 50 else doc for doc in documents],
                        hovertemplate='<b>Documento:</b> %{text}<br>' +
                                    '<b>Coordenadas:</b> (%{x:.2f}, %{y:.2f})<extra></extra>',
                        name=method.upper(),
                        showlegend=False
                    ),
                    row=1, col=i+1
                )
            
            # Configurar layout
            fig.update_layout(
                title=f"Compara√ß√£o de M√©todos de Redu√ß√£o - {collection_name}",
                width=1200,
                height=400,
                showlegend=False
            )
            
            logger.info(f"‚úÖ Visualiza√ß√µes 2D criadas para '{collection_name}'")
            return fig
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar visualiza√ß√µes 2D: {e}")
            return None
    
    def analyze_similarity(self, collection_name: str, n_samples: int = 10, max_documents: int = 1000) -> Dict[str, Any]:
        """Analisa similaridade entre documentos com otimiza√ß√£o de mem√≥ria"""
        try:
            embeddings = self.embeddings[collection_name]
            documents = self.documents[collection_name]
            
            # üö® OTIMIZA√á√ÉO DE MEM√ìRIA: Limitar n√∫mero de documentos para an√°lise
            total_docs = len(embeddings)
            if total_docs > max_documents:
                logger.warning(f"‚ö†Ô∏è Cole√ß√£o muito grande ({total_docs} documentos)")
                logger.info(f"üí° Limitando an√°lise para {max_documents} documentos para economizar mem√≥ria")
                logger.info(f"üí° Use 'max_documents' maior se tiver mais RAM dispon√≠vel")
                
                # Amostragem aleat√≥ria para economizar mem√≥ria
                import random
                random.seed(42)  # Para reprodutibilidade
                indices = random.sample(range(total_docs), max_documents)
                embeddings_sample = embeddings[indices]
                documents_sample = [documents[i] for i in indices]
                actual_n_samples = min(n_samples, max_documents)
            else:
                embeddings_sample = embeddings
                documents_sample = documents
                actual_n_samples = n_samples
            
            logger.info(f"üîç Analisando similaridade para {len(embeddings_sample)} documentos...")
            
            # Calcular matriz de similaridade (cosseno) com otimiza√ß√£o de mem√≥ria
            try:
                # Normalizar embeddings
                embeddings_norm = embeddings_sample / np.linalg.norm(embeddings_sample, axis=1, keepdims=True)
                
                # Calcular similaridade em chunks para economizar mem√≥ria
                chunk_size = min(100, len(embeddings_sample))
                similarity_matrix = np.zeros((len(embeddings_sample), len(embeddings_sample)), dtype=np.float32)
                
                for i in range(0, len(embeddings_sample), chunk_size):
                    end_i = min(i + chunk_size, len(embeddings_sample))
                    for j in range(0, len(embeddings_sample), chunk_size):
                        end_j = min(j + chunk_size, len(embeddings_sample))
                        chunk_similarity = np.dot(embeddings_norm[i:end_i], embeddings_norm[j:end_j].T)
                        similarity_matrix[i:end_i, j:end_j] = chunk_similarity
                
                logger.info(f"‚úÖ Matriz de similaridade calculada com sucesso")
                
            except MemoryError as e:
                logger.error(f"‚ùå Erro de mem√≥ria ao calcular similaridade: {e}")
                logger.info("üí° Tentando m√©todo alternativo com amostragem menor...")
                
                # Fallback: usar apenas uma amostra muito pequena
                max_docs_fallback = min(100, total_docs)
                indices_fallback = random.sample(range(total_docs), max_docs_fallback)
                embeddings_fallback = embeddings[indices_fallback]
                documents_fallback = [documents[i] for i in indices_fallback]
                
                embeddings_norm_fallback = embeddings_fallback / np.linalg.norm(embeddings_fallback, axis=1, keepdims=True)
                similarity_matrix = np.dot(embeddings_norm_fallback, embeddings_norm_fallback.T)
                embeddings_sample = embeddings_fallback
                documents_sample = documents_fallback
                actual_n_samples = min(n_samples, max_docs_fallback)
                
                logger.info(f"‚úÖ Usando amostra reduzida de {max_docs_fallback} documentos")
            
            # Encontrar documentos mais similares
            np.fill_diagonal(similarity_matrix, 0)  # Remover auto-similaridade
            
            analysis = {
                'similarity_matrix': similarity_matrix,
                'most_similar_pairs': [],
                'average_similarity': np.mean(similarity_matrix),
                'similarity_std': np.std(similarity_matrix),
                'total_documents_analyzed': len(embeddings_sample),
                'total_documents_original': total_docs,
                'memory_optimized': total_docs > max_documents
            }
            
            # Encontrar pares mais similares
            for i in range(min(actual_n_samples, len(documents_sample))):
                most_similar_idx = np.argmax(similarity_matrix[i])
                similarity_score = similarity_matrix[i][most_similar_idx]
                
                analysis['most_similar_pairs'].append({
                    'doc1': documents_sample[i][:100] + "..." if len(documents_sample[i]) > 100 else documents_sample[i],
                    'doc2': documents_sample[most_similar_idx][:100] + "..." if len(documents_sample[most_similar_idx]) > 100 else documents_sample[most_similar_idx],
                    'similarity': float(similarity_score)
                })
            
            logger.info(f"‚úÖ An√°lise de similaridade conclu√≠da para '{collection_name}'")
            logger.info(f"   - Documentos analisados: {len(embeddings_sample)}/{total_docs}")
            logger.info(f"   - Similaridade m√©dia: {analysis['average_similarity']:.3f}")
            logger.info(f"   - Desvio padr√£o: {analysis['similarity_std']:.3f}")
            if analysis['memory_optimized']:
                logger.info(f"   - ‚ö° Otimiza√ß√£o de mem√≥ria aplicada")
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise de similaridade: {e}")
            if "Unable to allocate" in str(e):
                logger.error("üí° DICA: Cole√ß√£o muito grande para an√°lise completa")
                logger.info("üí° Solu√ß√µes:")
                logger.info("   1. Use op√ß√£o 5 (Relat√≥rio Completo) que otimiza automaticamente")
                logger.info("   2. Reduza o n√∫mero de documentos na cole√ß√£o")
                logger.info("   3. Execute em um sistema com mais RAM")
            return None
    
    def create_similarity_heatmap(self, collection_name: str, analysis: Dict[str, Any]) -> go.Figure:
        """Cria heatmap da matriz de similaridade"""
        try:
            similarity_matrix = analysis['similarity_matrix']
            
            # Criar heatmap
            fig = go.Figure(data=go.Heatmap(
                z=similarity_matrix,
                colorscale='Viridis',
                zmid=0.5,
                colorbar=dict(title="Similaridade (Cosseno)")
            ))
            
            fig.update_layout(
                title=f"Matriz de Similaridade - {collection_name}",
                xaxis_title="Documento",
                yaxis_title="Documento",
                width=800,
                height=600
            )
            
            logger.info(f"‚úÖ Heatmap de similaridade criado para '{collection_name}'")
            return fig
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar heatmap: {e}")
            return None
    
    def export_visualization(self, fig: go.Figure, filename: str, format: str = "html"):
        """Exporta visualiza√ß√£o para arquivo"""
        try:
            if format.lower() == "html":
                fig.write_html(f"{filename}.html")
                logger.info(f"‚úÖ Visualiza√ß√£o exportada para: {filename}.html")
            elif format.lower() == "png":
                fig.write_image(f"{filename}.png")
                logger.info(f"‚úÖ Visualiza√ß√£o exportada para: {filename}.png")
            elif format.lower() == "pdf":
                fig.write_image(f"{filename}.pdf")
                logger.info(f"‚úÖ Visualiza√ß√£o exportada para: {filename}.pdf")
            else:
                logger.warning(f"‚ö†Ô∏è Formato n√£o suportado: {format}")
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao exportar visualiza√ß√£o: {e}")
    
    def generate_report(self, collection_name: str, output_dir: str = "visualizations"):
        """Gera relat√≥rio completo de visualiza√ß√µes"""
        try:
            output_path = Path(output_dir)
            output_path.mkdir(exist_ok=True)
            
            logger.info(f"üìä Gerando relat√≥rio completo para '{collection_name}'...")
            
            # 1. Visualiza√ß√£o 3D com PCA
            fig_3d_pca = self.create_3d_scatter(collection_name, "pca")
            if fig_3d_pca:
                self.export_visualization(fig_3d_pca, output_path / f"{collection_name}_3d_pca")
            
            # 2. Visualiza√ß√£o 3D com UMAP
            fig_3d_umap = self.create_3d_scatter(collection_name, "umap")
            if fig_3d_umap:
                self.export_visualization(fig_3d_umap, output_path / f"{collection_name}_3d_umap")
            
            # 3. Compara√ß√£o 2D
            fig_2d = self.create_2d_visualizations(collection_name)
            if fig_2d:
                self.export_visualization(fig_2d, output_path / f"{collection_name}_2d_comparison")
            
            # 4. An√°lise de similaridade
            analysis = self.analyze_similarity(collection_name)
            if analysis:
                # Salvar dados de an√°lise
                with open(output_path / f"{collection_name}_similarity_analysis.json", 'w', encoding='utf-8') as f:
                    json.dump({
                        'average_similarity': analysis['average_similarity'],
                        'similarity_std': analysis['similarity_std'],
                        'most_similar_pairs': analysis['most_similar_pairs']
                    }, f, indent=2, ensure_ascii=False)
                
                # Criar heatmap
                fig_heatmap = self.create_similarity_heatmap(collection_name, analysis)
                if fig_heatmap:
                    self.export_visualization(fig_heatmap, output_path / f"{collection_name}_similarity_heatmap")
            
            # 5. Relat√≥rio HTML
            self.create_html_report(collection_name, output_path, analysis)
            
            logger.info(f"‚úÖ Relat√≥rio completo gerado em: {output_path}")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar relat√≥rio: {e}")
    
    def create_html_report(self, collection_name: str, output_path: Path, analysis: Dict[str, Any]):
        """Cria relat√≥rio HTML completo"""
        try:
            html_content = f"""
            <!DOCTYPE html>
            <html lang="pt-BR">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>Relat√≥rio de Visualiza√ß√£o - {collection_name}</title>
                <style>
                    body {{ font-family: Arial, sans-serif; margin: 20px; }}
                    .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; }}
                    .section {{ margin: 20px 0; padding: 20px; border: 1px solid #ddd; border-radius: 8px; }}
                    .metric {{ display: inline-block; margin: 10px; padding: 15px; background: #f8f9fa; border-radius: 5px; }}
                    .similarity-pair {{ margin: 10px 0; padding: 10px; background: #e9ecef; border-radius: 5px; }}
                    iframe {{ width: 100%; height: 600px; border: none; }}
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>üîç Relat√≥rio de Visualiza√ß√£o do Banco de Dados Vetorial</h1>
                    <h2>Cole√ß√£o: {collection_name}</h2>
                    <p>Gerado em: {time.strftime('%d/%m/%Y %H:%M:%S')}</p>
                </div>
                
                <div class="section">
                    <h3>üìä M√©tricas Gerais</h3>
                    <div class="metric">
                        <strong>Total de Documentos:</strong> {len(self.documents[collection_name])}
                    </div>
                    <div class="metric">
                        <strong>Dimens√µes dos Embeddings:</strong> {self.embeddings[collection_name].shape[1]}
                    </div>
                    <div class="metric">
                        <strong>Similaridade M√©dia:</strong> {analysis['average_similarity']:.3f if analysis else 'N/A'}
                    </div>
                    <div class="metric">
                        <strong>Desvio Padr√£o:</strong> {analysis['similarity_std']:.3f if analysis else 'N/A'}
                    </div>
                </div>
                
                <div class="section">
                    <h3>üéØ Visualiza√ß√£o 3D - PCA</h3>
                    <iframe src="{collection_name}_3d_pca.html"></iframe>
                </div>
                
                <div class="section">
                    <h3>üåå Visualiza√ß√£o 3D - UMAP</h3>
                    <iframe src="{collection_name}_3d_umap.html"></iframe>
                </div>
                
                <div class="section">
                    <h3>üìà Compara√ß√£o de M√©todos 2D</h3>
                    <iframe src="{collection_name}_2d_comparison.html"></iframe>
                </div>
                
                <div class="section">
                    <h3>üî• Matriz de Similaridade</h3>
                    <iframe src="{collection_name}_similarity_heatmap.html"></iframe>
                </div>
                
                <div class="section">
                    <h3>üîó Documentos Mais Similares</h3>
                    {self._generate_similarity_html(analysis) if analysis else '<p>An√°lise n√£o dispon√≠vel</p>'}
                </div>
            </body>
            </html>
            """
            
            with open(output_path / f"{collection_name}_report.html", 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"‚úÖ Relat√≥rio HTML criado: {output_path / f'{collection_name}_report.html'}")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar relat√≥rio HTML: {e}")
    
    def _generate_similarity_html(self, analysis: Dict[str, Any]) -> str:
        """Gera HTML para pares similares"""
        html = ""
        for pair in analysis['most_similar_pairs'][:10]:  # Top 10
            html += f"""
            <div class="similarity-pair">
                <strong>Similaridade: {pair['similarity']:.3f}</strong><br>
                <strong>Doc 1:</strong> {pair['doc1']}<br>
                <strong>Doc 2:</strong> {pair['doc2']}
            </div>
            """
        return html


def get_user_input(prompt: str, valid_options: List[str] = None, input_type: str = "text") -> Any:
    """Fun√ß√£o auxiliar para obter entrada do usu√°rio com valida√ß√£o"""
    while True:
        try:
            if input_type == "int":
                user_input = int(input(prompt))
                if valid_options and user_input not in valid_options:
                    print(f"‚ùå Por favor, escolha uma op√ß√£o v√°lida: {valid_options}")
                    continue
                return user_input
            elif input_type == "float":
                return float(input(prompt))
            elif input_type == "bool":
                user_input = input(prompt).lower().strip()
                if user_input in ['s', 'sim', 'y', 'yes', 'true', '1']:
                    return True
                elif user_input in ['n', 'n√£o', 'nao', 'no', 'false', '0']:
                    return False
                else:
                    print("‚ùå Por favor, responda com 's' (sim) ou 'n' (n√£o)")
                    continue
            else:
                user_input = input(prompt).strip()
                if not user_input:
                    print("‚ùå Por favor, digite algo v√°lido")
                    continue
                return user_input
        except ValueError:
            print("‚ùå Entrada inv√°lida. Tente novamente.")
        except KeyboardInterrupt:
            print("\nüëã Interrompido pelo usu√°rio")
            sys.exit(0)


def main():
    """Fun√ß√£o principal para executar o visualizador"""
    print("üîç Visualizador 3D do Banco de Dados Vetorial")
    print("=" * 60)
    print("üìñ Este programa permite visualizar e analisar o banco de dados vetorial")
    print("   do sistema RAG em 3D, incluindo clustering e an√°lise de similaridade.")
    print()
    
    # Inicializar visualizador
    visualizer = VectorDBVisualizer()
    
    # Conectar ao ChromaDB
    print("üîå Conectando ao banco de dados vetorial...")
    if not visualizer.connect_to_chromadb():
        print("‚ùå Falha ao conectar ao ChromaDB")
        print("üí° Verifique se o diret√≥rio 'data/.chromadb' existe e cont√©m dados v√°lidos")
        return
    
    # Listar cole√ß√µes dispon√≠veis
    collections = visualizer.client.list_collections()
    if not collections:
        print("‚ùå Nenhuma cole√ß√£o encontrada no banco de dados")
        print("üí° O banco de dados pode estar vazio ou n√£o foi inicializado corretamente")
        return
    
    print(f"\nüìö Cole√ß√µes dispon√≠veis no banco de dados:")
    for i, collection in enumerate(collections):
        doc_count = collection.count()
        print(f"   {i+1}. {collection.name} ({doc_count} documentos)")
    
    # Selecionar cole√ß√£o com valida√ß√£o
    print(f"\nüéØ Selecione uma cole√ß√£o para visualizar:")
    print("   üí° Digite o n√∫mero da cole√ß√£o desejada")
    
    try:
        choice = get_user_input(
            f"   Escolha (1-{len(collections)}): ", 
            list(range(1, len(collections) + 1)), 
            "int"
        )
        
        selected_collection = collections[choice - 1].name
        print(f"‚úÖ Cole√ß√£o selecionada: {selected_collection}")
        
    except (ValueError, IndexError):
        print("‚ùå Escolha inv√°lida")
        return
    
    # Carregar dados da cole√ß√£o
    print(f"\nüì• Carregando dados da cole√ß√£o '{selected_collection}'...")
    if not visualizer.load_collection_data(selected_collection):
        print("‚ùå Falha ao carregar dados da cole√ß√£o")
        return
    
    print(f"‚úÖ Dados carregados com sucesso!")
    print(f"   üìä Total de documentos: {len(visualizer.documents[selected_collection])}")
    print(f"   üß† Dimens√µes dos embeddings: {visualizer.embeddings[selected_collection].shape[1]}")
    
    # Menu principal de op√ß√µes
    while True:
        print(f"\nüîß Menu de Visualiza√ß√µes - {selected_collection}")
        print("=" * 50)
        print("1. üéØ Visualiza√ß√£o 3D (PCA)")
        print("   üí° Mostra documentos em 3D usando An√°lise de Componentes Principais")
        print("   üìä Inclui clustering autom√°tico dos documentos")
        print()
        print("2. üåå Visualiza√ß√£o 3D (UMAP)")
        print("   üí° Visualiza√ß√£o 3D usando UMAP para melhor preserva√ß√£o de estrutura")
        print("   üé® Ideal para an√°lise de clusters e relacionamentos")
        print()
        print("3. üìà Compara√ß√£o 2D (PCA, t-SNE, UMAP)")
        print("   üí° Compara diferentes m√©todos de redu√ß√£o de dimensionalidade")
        print("   üîç √ötil para escolher o melhor m√©todo para seus dados")
        print()
        print("4. üîó An√°lise de Similaridade")
        print("   üí° Analisa como os documentos se relacionam entre si")
        print("   üìä Inclui matriz de similaridade e pares mais similares")
        print()
        print("5. üìä Gerar Relat√≥rio Completo")
        print("   üí° Cria todas as visualiza√ß√µes e salva em arquivos")
        print("   üìÅ Salva em HTML, PNG e PDF para uso posterior")
        print()
        print("6. üö™ Sair")
        print("   üí° Encerra o programa")
        print()
        
        try:
            option = get_user_input("üéØ Escolha uma op√ß√£o (1-6): ", list(range(1, 7)), "int")
            
            if option == 1:
                print(f"\nüéØ Criando visualiza√ß√£o 3D com PCA...")
                print("   üí° PCA preserva a vari√¢ncia m√°xima dos dados")
                print("   ‚è≥ Isso pode levar alguns segundos para cole√ß√µes grandes...")
                
                fig = visualizer.create_3d_scatter(selected_collection, "pca")
                if fig:
                    print("‚úÖ Visualiza√ß√£o 3D criada com sucesso!")
                    print("   üñ±Ô∏è Use o mouse para rotacionar, zoom e pan")
                    print("   üì± Toque e arraste em dispositivos touch")
                    fig.show()
                    
                    save = get_user_input("üíæ Salvar visualiza√ß√£o? (s/n): ", input_type="bool")
                    if save:
                        filename = get_user_input("üìù Nome do arquivo (sem extens√£o): ")
                        if filename:
                            visualizer.export_visualization(fig, filename, "html")
                            print(f"‚úÖ Visualiza√ß√£o salva como: {filename}.html")
                else:
                    print("‚ùå Falha ao criar visualiza√ß√£o 3D")
            
            elif option == 2:
                print(f"\nüåå Criando visualiza√ß√£o 3D com UMAP...")
                print("   üí° UMAP preserva melhor a estrutura local dos dados")
                print("   ‚è≥ Processando... (pode demorar para cole√ß√µes grandes)")
                
                fig = visualizer.create_3d_scatter(selected_collection, "umap")
                if fig:
                    print("‚úÖ Visualiza√ß√£o 3D UMAP criada com sucesso!")
                    print("   üñ±Ô∏è Use o mouse para rotacionar, zoom e pan")
                    print("   üì± Toque e arraste em dispositivos touch")
                    fig.show()
                    
                    save = get_user_input("üíæ Salvar visualiza√ß√£o? (s/n): ", input_type="bool")
                    if save:
                        filename = get_user_input("üìù Nome do arquivo (sem extens√£o): ")
                        if filename:
                            visualizer.export_visualization(fig, filename, "html")
                            print(f"‚úÖ Visualiza√ß√£o salva como: {filename}.html")
                else:
                    print("‚ùå Falha ao criar visualiza√ß√£o 3D UMAP")
            
            elif option == 3:
                print(f"\nüìà Criando compara√ß√£o de m√©todos 2D...")
                print("   üí° Comparando PCA, t-SNE e UMAP para 2 dimens√µes")
                print("   ‚è≥ Processando... (pode demorar para cole√ß√µes grandes)")
                
                fig = visualizer.create_2d_visualizations(selected_collection)
                if fig:
                    print("‚úÖ Compara√ß√£o 2D criada com sucesso!")
                    print("   üìä PCA: Preserva vari√¢ncia global")
                    print("   üéØ t-SNE: Foca em estrutura local")
                    print("   üåå UMAP: Equilibra local e global")
                    fig.show()
                    
                    save = get_user_input("üíæ Salvar compara√ß√£o? (s/n): ", input_type="bool")
                    if save:
                        filename = get_user_input("üìù Nome do arquivo (sem extens√£o): ")
                        if filename:
                            visualizer.export_visualization(fig, filename, "html")
                            print(f"‚úÖ Compara√ß√£o salva como: {filename}.html")
                else:
                    print("‚ùå Falha ao criar compara√ß√£o 2D")
            
            elif option == 4:
                print(f"\nüîó Analisando similaridade entre documentos...")
                print("   üí° Calculando matriz de similaridade usando cosseno")
                print("   ‚è≥ Processando...")
                
                analysis = visualizer.analyze_similarity(selected_collection)
                if analysis:
                    print("‚úÖ An√°lise de similaridade conclu√≠da!")
                    print(f"\nüìä M√©tricas de Similaridade:")
                    print(f"   - M√©dia: {analysis['average_similarity']:.3f}")
                    print(f"   - Desvio Padr√£o: {analysis['similarity_std']:.3f}")
                    
                    print(f"\nüîó Top 5 Pares Mais Similares:")
                    for i, pair in enumerate(analysis['most_similar_pairs'][:5]):
                        print(f"   {i+1}. Similaridade: {pair['similarity']:.3f}")
                        print(f"      üìÑ Doc 1: {pair['doc1'][:80]}...")
                        print(f"      üìÑ Doc 2: {pair['doc2'][:80]}...")
                        print()
                    
                    # Criar e mostrar heatmap
                    print("üî• Criando heatmap de similaridade...")
                    fig = visualizer.create_similarity_heatmap(selected_collection, analysis)
                    if fig:
                        print("‚úÖ Heatmap criado com sucesso!")
                        print("   üî• Cores mais quentes = maior similaridade")
                        print("   ‚ùÑÔ∏è Cores mais frias = menor similaridade")
                        fig.show()
                        
                        save = get_user_input("üíæ Salvar heatmap? (s/n): ", input_type="bool")
                        if save:
                            filename = get_user_input("üìù Nome do arquivo (sem extens√£o): ")
                            if filename:
                                visualizer.export_visualization(fig, filename, "html")
                                print(f"‚úÖ Heatmap salvo como: {filename}.html")
                    else:
                        print("‚ùå Falha ao criar heatmap")
                else:
                    print("‚ùå Falha na an√°lise de similaridade")
            
            elif option == 5:
                print(f"\nüìä Gerando relat√≥rio completo...")
                print("   üí° Criando todas as visualiza√ß√µes dispon√≠veis")
                print("   üìÅ Salvando em pasta 'visualizations'")
                print("   ‚è≥ Isso pode levar alguns minutos...")
                
                try:
                    visualizer.generate_report(selected_collection)
                    print("‚úÖ Relat√≥rio completo gerado com sucesso!")
                    print("   üìÅ Pasta: visualizations/")
                    print("   üìÑ Arquivo principal: visualizations/{selected_collection}_report.html")
                    print("   üéØ Abra o arquivo HTML no seu navegador para ver tudo")
                except Exception as e:
                    print(f"‚ùå Erro ao gerar relat√≥rio: {e}")
            
            elif option == 6:
                print("\nüìö Explicando M√©todos de Redu√ß√£o de Dimensionalidade...")
                print("=" * 60)
                
                explanation = """
üîç **O QUE S√ÉO ESSES M√âTODOS E POR QUE S√ÉO IMPORTANTES?**

üìö **CONTEXTO: O PROBLEMA DOS DADOS VETORIAIS**

Imagine que cada documento do seu banco de dados √© como um ponto no espa√ßo, mas n√£o um espa√ßo normal de 3 dimens√µes (altura, largura, profundidade). 
√â um espa√ßo de MUITAS dimens√µes - pode ter 1536, 4096 ou at√© mais dimens√µes!

üí° **POR QUE ISSO √â UM PROBLEMA?**
- Humanos s√≥ conseguem visualizar 2D ou 3D
- Computadores t√™m dificuldade com tantas dimens√µes
- √â como tentar entender um cubo de 1536 dimens√µes!

üéØ **SOLU√á√ÉO: REDU√á√ÉO DE DIMENSIONALIDADE**

Os m√©todos PCA, UMAP e t-SNE s√£o como "tradutores" que pegam esses pontos em muitas dimens√µes 
e os colocam em 2D ou 3D, mantendo o m√°ximo poss√≠vel de informa√ß√£o importante.

---

üîß **PCA (AN√ÅLISE DE COMPONENTES PRINCIPAIS)**

üí≠ **EXPLICA√á√ÉO SIMPLES:**
Imagine que voc√™ tem uma foto de um rosto em alta resolu√ß√£o (muitos pixels). 
PCA √© como criar uma vers√£o "resumida" dessa foto, mantendo apenas os detalhes mais importantes.

üéØ **O QUE FAZ:**
- Pega os dados em muitas dimens√µes
- Identifica as "dire√ß√µes" mais importantes (onde h√° mais varia√ß√£o)
- Projeta tudo nessas dire√ß√µes principais
- Resultado: 2D ou 3D que preserva a "ess√™ncia" dos dados

‚úÖ **VANTAGENS:**
- R√°pido e eficiente
- Preserva a estrutura global dos dados
- Bom para encontrar padr√µes gerais

‚ùå **LIMITA√á√ïES:**
- Pode perder detalhes locais importantes
- N√£o √© muito bom para encontrar grupos pequenos

---

üåå **UMAP (UNIFORM MANIFOLD APPROXIMATION AND PROJECTION)**

üí≠ **EXPLICA√á√ÉO SIMPLES:**
Imagine que voc√™ tem um mapa de uma cidade com muitas ruas. UMAP √© como criar um mapa simplificado 
que mostra os bairros principais e como eles se conectam, mantendo as dist√¢ncias relativas.

üéØ **O QUE FAZ:**
- Preserva tanto a estrutura local quanto global
- Cria uma "rede" que conecta pontos similares
- Mant√©m as rela√ß√µes de proximidade entre documentos

‚úÖ **VANTAGENS:**
- Preserva melhor a estrutura local dos dados
- Excelente para encontrar clusters (grupos)
- Bom para visualiza√ß√£o interativa
- Mais r√°pido que t-SNE

‚ùå **LIMITA√á√ïES:**
- Pode ser menos est√°vel que PCA
- Par√¢metros podem afetar o resultado

---

üéØ **T-SNE (T-DISTRIBUTED STOCHASTIC NEIGHBOR EMBEDDING)**

üí≠ **EXPLICA√á√ÉO SIMPLES:**
Imagine que voc√™ tem um grupo de pessoas em uma sala. T-SNE √© como reorganizar essas pessoas 
em uma sala menor, colocando amigos pr√≥ximos uns dos outros e estranhos mais distantes.

üéØ **O QUE FAZ:**
- Foca na preserva√ß√£o de dist√¢ncias locais
- Coloca documentos similares pr√≥ximos
- Separa bem grupos diferentes

‚úÖ **VANTAGENS:**
- Excelente para encontrar clusters
- Preserva muito bem a estrutura local
- √ìtimo para visualizar grupos de documentos similares

‚ùå **LIMITA√á√ïES:**
- Pode distorcer a estrutura global
- Mais lento que PCA e UMAP
- Resultado pode variar entre execu√ß√µes

---

üöÄ **IMPORT√ÇNCIA NO BANCO DE DADOS VETORIAL**

üí° **POR QUE ISSO √â CR√çTICO?**

1. **VISUALIZA√á√ÉO HUMANA:**
   - Humanos s√≥ conseguem ver 2D/3D
   - Sem redu√ß√£o, √© imposs√≠vel "ver" os dados

2. **AN√ÅLISE DE CLUSTERS:**
   - Documentos similares ficam pr√≥ximos
   - F√°cil identificar grupos de conte√∫do relacionado

3. **QUALIDADE DOS DADOS:**
   - Revela se os embeddings est√£o funcionando bem
   - Mostra se documentos similares est√£o realmente pr√≥ximos

4. **DEBUGGING DO SISTEMA:**
   - Identifica problemas na indexa√ß√£o
   - Mostra se o banco est√° organizado corretamente

5. **OTIMIZA√á√ÉO:**
   - Ajuda a ajustar par√¢metros do sistema
   - Mostra onde melhorar a qualidade dos embeddings

---

üé® **COMO INTERPRETAR OS RESULTADOS**

üîç **GRUPOS BEM DEFINIDOS:**
- Documentos similares est√£o pr√≥ximos
- Clusters claros e separados
- Sistema funcionando bem

‚ö†Ô∏è **GRUPOS DIFUSOS:**
- Documentos similares espalhados
- Clusters mal definidos
- Poss√≠vel problema nos embeddings

üéØ **RECOMENDA√á√ïES DE USO:**

- **PCA:** Para vis√£o geral e an√°lise inicial
- **UMAP:** Para an√°lise detalhada e interativa
- **T-SNE:** Para encontrar grupos espec√≠ficos

---

üí° **DICA IMPORTANTE:**
Esses m√©todos n√£o "criam" informa√ß√£o - eles apenas reorganizam o que j√° existe. 
Se seus documentos n√£o est√£o bem organizados no espa√ßo vetorial original, 
a redu√ß√£o de dimensionalidade n√£o vai "consertar" isso!

---

üéØ **NO SEU CASO ESPEC√çFICO:**

Voc√™ tem uma cole√ß√£o com {doc_count} documentos, cada um representado por um vetor de {embedding_dims} dimens√µes.

Isso significa que:
- Cada documento √© um ponto em um espa√ßo de {embedding_dims} dimens√µes
- √â imposs√≠vel "ver" essa estrutura sem redu√ß√£o de dimensionalidade
- Os m√©todos PCA, UMAP e t-SNE v√£o te permitir "ver" como seus documentos se organizam
- Voc√™ poder√° identificar se documentos sobre o mesmo tema est√£o realmente pr√≥ximos
- Poder√° ver se h√° problemas na organiza√ß√£o do seu banco vetorial

---

üöÄ **PR√ìXIMOS PASSOS:**

1. **Teste PCA primeiro** (op√ß√£o 1) - para vis√£o geral
2. **Teste UMAP** (op√ß√£o 2) - para an√°lise detalhada
3. **Compare os m√©todos** (op√ß√£o 3) - para entender as diferen√ßas
4. **Analise similaridade** (op√ß√£o 4) - para ver relacionamentos
5. **Gere relat√≥rio completo** (op√ß√£o 5) - para ter tudo salvo
                """.format(
                    doc_count=len(visualizer.documents[selected_collection]),
                    embedding_dims=visualizer.embeddings[selected_collection].shape[1]
                )
                
                # Mostrar explica√ß√£o em partes para facilitar leitura
                lines = explanation.strip().split('\n')
                for line in lines:
                    if line.strip():
                        print(line)
                    else:
                        print()
                    
                    # Pausa para facilitar leitura
                    if line.startswith('---'):
                        input("\n‚è∏Ô∏è Pressione ENTER para continuar...")
                
                print("\n‚úÖ Explica√ß√£o conclu√≠da!")
                print("üí° Agora voc√™ entende por que esses m√©todos s√£o importantes!")
                print("üéØ Use as op√ß√µes 1-5 para explorar seu banco de dados vetorial")
            
            elif option == 7:
                print("\nüëã Encerrando o visualizador...")
                print("   üí° Obrigado por usar o sistema de visualiza√ß√£o!")
                print("   üìÅ Lembre-se de verificar a pasta 'visualizations' para os arquivos salvos")
                break
            
            else:
                print("‚ùå Op√ß√£o inv√°lida. Por favor, escolha de 1 a 6.")
                
        except ValueError as e:
            print(f"‚ùå Erro de entrada: {e}")
        except KeyboardInterrupt:
            print("\nüëã Interrompido pelo usu√°rio")
            break
        except Exception as e:
            print(f"‚ùå Erro inesperado: {e}")
            print("üí° Tente novamente ou escolha outra op√ß√£o")


if __name__ == "__main__":
    main()
