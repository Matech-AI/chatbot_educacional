#!/usr/bin/env python3
"""
Visualizador 3D do Banco de Dados Vetorial (ChromaDB)
Permite visualizar os embeddings dos documentos em 3D para anÃ¡lise e debug.

Funcionalidades:
- VisualizaÃ§Ã£o 3D com PCA, t-SNE e UMAP
- Clustering automÃ¡tico dos documentos
- Interatividade com plotly
- AnÃ¡lise de similaridade entre documentos
- ExportaÃ§Ã£o de visualizaÃ§Ãµes

Autor: Sistema RAG DNA da ForÃ§a
"""

import os
import sys
import logging
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import json
import time

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Adicionar o diretÃ³rio raiz ao path para imports
sys.path.append(str(Path(__file__).parent))

try:
    import chromadb
    from chromadb.config import Settings
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.subplots import make_subplots
    import plotly.offline as pyo
    from sklearn.decomposition import PCA
    from sklearn.manifold import TSNE
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    import umap
    from collections import defaultdict
    import matplotlib.pyplot as plt
    import seaborn as sns
except ImportError as e:
    logger.error(f"âŒ DependÃªncias nÃ£o encontradas: {e}")
    logger.info("ğŸ’¡ Instale com: pip install plotly scikit-learn umap-learn matplotlib seaborn")
    sys.exit(1)

class VectorDBVisualizer:
    """Visualizador 3D do banco de dados vetorial"""
    
    def __init__(self, persist_dir: str = "data/.chromadb"):
        self.persist_dir = Path(persist_dir)
        self.client = None
        self.collections = {}
        self.embeddings = {}
        self.metadata = {}
        self.documents = {}
        
    def connect_to_chromadb(self) -> bool:
        """Conecta ao ChromaDB e carrega as coleÃ§Ãµes"""
        try:
            if not self.persist_dir.exists():
                logger.error(f"âŒ DiretÃ³rio ChromaDB nÃ£o encontrado: {self.persist_dir}")
                return False
                
            # Conectar ao ChromaDB
            self.client = chromadb.PersistentClient(path=str(self.persist_dir))
            logger.info(f"âœ… Conectado ao ChromaDB em: {self.persist_dir}")
            
            # Listar coleÃ§Ãµes
            collections = self.client.list_collections()
            logger.info(f"ğŸ“š ColeÃ§Ãµes encontradas: {len(collections)}")
            
            for collection in collections:
                logger.info(f"   - {collection.name}: {collection.count()} documentos")
                
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erro ao conectar ao ChromaDB: {e}")
            return False
    
    def load_collection_data(self, collection_name: str) -> bool:
        """Carrega dados de uma coleÃ§Ã£o especÃ­fica"""
        try:
            collection = self.client.get_collection(collection_name)
            
            # Obter todos os documentos
            results = collection.get(
                include=['embeddings', 'documents', 'metadatas']
            )
            
            self.collections[collection_name] = collection
            self.embeddings[collection_name] = np.array(results['embeddings'])
            self.documents[collection_name] = results['documents']
            self.metadata[collection_name] = results['metadatas']
            
            logger.info(f"âœ… ColeÃ§Ã£o '{collection_name}' carregada:")
            logger.info(f"   - Embeddings: {self.embeddings[collection_name].shape}")
            logger.info(f"   - Documentos: {len(self.documents[collection_name])}")
            logger.info(f"   - Metadados: {len(self.metadata[collection_name])}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erro ao carregar coleÃ§Ã£o '{collection_name}': {e}")
            return False
    
    def reduce_dimensions(self, embeddings: np.ndarray, method: str = "pca", n_components: int = 3) -> np.ndarray:
        """Reduz dimensionalidade dos embeddings para visualizaÃ§Ã£o"""
        try:
            logger.info(f"ğŸ”§ Reduzindo dimensionalidade com {method.upper()}...")
            
            if method.lower() == "pca":
                reducer = PCA(n_components=n_components, random_state=42)
                reduced = reducer.fit_transform(embeddings)
                explained_variance = reducer.explained_variance_ratio_
                logger.info(f"âœ… PCA: VariÃ¢ncia explicada: {explained_variance}")
                
            elif method.lower() == "tsne":
                reducer = TSNE(n_components=n_components, random_state=42, perplexity=min(30, len(embeddings)-1))
                reduced = reducer.fit_transform(embeddings)
                logger.info(f"âœ… t-SNE: Dimensionalidade reduzida para {n_components}D")
                
            elif method.lower() == "umap":
                reducer = umap.UMAP(n_components=n_components, random_state=42, n_neighbors=min(15, len(embeddings)-1))
                reduced = reducer.fit_transform(embeddings)
                logger.info(f"âœ… UMAP: Dimensionalidade reduzida para {n_components}D")
                
            else:
                raise ValueError(f"MÃ©todo nÃ£o suportado: {method}")
            
            return reduced
            
        except Exception as e:
            logger.error(f"âŒ Erro na reduÃ§Ã£o de dimensionalidade: {e}")
            return None
    
    def cluster_documents(self, embeddings: np.ndarray, n_clusters: int = 5) -> np.ndarray:
        """Aplica clustering K-means aos documentos"""
        try:
            logger.info(f"ğŸ¯ Aplicando clustering K-means com {n_clusters} clusters...")
            
            # Normalizar embeddings
            scaler = StandardScaler()
            embeddings_scaled = scaler.fit_transform(embeddings)
            
            # Aplicar K-means
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            clusters = kmeans.fit_predict(embeddings_scaled)
            
            logger.info(f"âœ… Clustering aplicado: {len(np.unique(clusters))} clusters")
            return clusters
            
        except Exception as e:
            logger.error(f"âŒ Erro no clustering: {e}")
            return None
    
    def create_3d_scatter(self, collection_name: str, method: str = "pca", n_clusters: int = 5) -> go.Figure:
        """Cria visualizaÃ§Ã£o 3D interativa dos embeddings"""
        try:
            embeddings = self.embeddings[collection_name]
            documents = self.documents[collection_name]
            metadata = self.metadata[collection_name]
            
            # Reduzir dimensionalidade
            reduced_embeddings = self.reduce_dimensions(embeddings, method)
            if reduced_embeddings is None:
                raise ValueError("Falha na reduÃ§Ã£o de dimensionalidade")
            
            # Aplicar clustering
            clusters = self.cluster_documents(embeddings, n_clusters)
            if clusters is None:
                clusters = np.zeros(len(embeddings), dtype=int)
            
            # Criar DataFrame para plotagem
            df = pd.DataFrame({
                'x': reduced_embeddings[:, 0],
                'y': reduced_embeddings[:, 1],
                'z': reduced_embeddings[:, 2],
                'cluster': clusters,
                'document': [doc[:100] + "..." if len(doc) > 100 else doc for doc in documents],
                'source': [meta.get('source', 'N/A') if meta else 'N/A' for meta in metadata]
            })
            
            # Criar figura 3D
            fig = go.Figure()
            
            # Adicionar pontos por cluster
            colors = px.colors.qualitative.Set3
            for cluster_id in sorted(df['cluster'].unique()):
                cluster_data = df[df['cluster'] == cluster_id]
                
                fig.add_trace(go.Scatter3d(
                    x=cluster_data['x'],
                    y=cluster_data['y'],
                    z=cluster_data['z'],
                    mode='markers',
                    marker=dict(
                        size=8,
                        color=colors[cluster_id % len(colors)],
                        opacity=0.8
                    ),
                    text=cluster_data['document'],
                    hovertemplate='<b>Documento:</b> %{text}<br>' +
                                '<b>Fonte:</b> %{customdata}<br>' +
                                '<b>Cluster:</b> ' + str(cluster_id) + '<br>' +
                                '<b>Coordenadas:</b> (%{x:.2f}, %{y:.2f}, %{z:.2f})<extra></extra>',
                    customdata=cluster_data['source'],
                    name=f'Cluster {cluster_id}',
                    showlegend=True
                ))
            
            # Configurar layout
            fig.update_layout(
                title=f"VisualizaÃ§Ã£o 3D - {collection_name} ({method.upper()})",
                scene=dict(
                    xaxis_title=f"{method.upper()} Componente 1",
                    yaxis_title=f"{method.upper()} Componente 2",
                    zaxis_title=f"{method.upper()} Componente 3",
                    camera=dict(
                        eye=dict(x=1.5, y=1.5, z=1.5)
                    )
                ),
                width=1000,
                height=800,
                showlegend=True
            )
            
            logger.info(f"âœ… VisualizaÃ§Ã£o 3D criada para '{collection_name}'")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ Erro ao criar visualizaÃ§Ã£o 3D: {e}")
            return None
    
    def create_2d_visualizations(self, collection_name: str) -> go.Figure:
        """Cria visualizaÃ§Ãµes 2D com diferentes mÃ©todos"""
        try:
            embeddings = self.embeddings[collection_name]
            documents = self.documents[collection_name]
            metadata = self.metadata[collection_name]
            
            # Reduzir dimensionalidade para 2D com diferentes mÃ©todos
            methods = ["pca", "tsne", "umap"]
            reduced_data = {}
            
            for method in methods:
                reduced = self.reduce_dimensions(embeddings, method, n_components=2)
                if reduced is not None:
                    reduced_data[method] = reduced
            
            # Criar subplots
            fig = make_subplots(
                rows=1, cols=len(reduced_data),
                subplot_titles=[f"{method.upper()}" for method in reduced_data.keys()],
                specs=[[{"type": "scatter"} for _ in reduced_data]]
            )
            
            # Adicionar pontos para cada mÃ©todo
            colors = px.colors.qualitative.Set3
            for i, (method, reduced) in enumerate(reduced_data.items()):
                fig.add_trace(
                    go.Scatter(
                        x=reduced[:, 0],
                        y=reduced[:, 1],
                        mode='markers',
                        marker=dict(
                            size=6,
                            color=colors[i % len(colors)],
                            opacity=0.7
                        ),
                        text=[doc[:50] + "..." if len(doc) > 50 else doc for doc in documents],
                        hovertemplate='<b>Documento:</b> %{text}<br>' +
                                    '<b>Coordenadas:</b> (%{x:.2f}, %{y:.2f})<extra></extra>',
                        name=method.upper(),
                        showlegend=False
                    ),
                    row=1, col=i+1
                )
            
            # Configurar layout
            fig.update_layout(
                title=f"ComparaÃ§Ã£o de MÃ©todos de ReduÃ§Ã£o - {collection_name}",
                width=1200,
                height=400,
                showlegend=False
            )
            
            logger.info(f"âœ… VisualizaÃ§Ãµes 2D criadas para '{collection_name}'")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ Erro ao criar visualizaÃ§Ãµes 2D: {e}")
            return None
    
    def analyze_similarity(self, collection_name: str, n_samples: int = 10, max_documents: int = 1000) -> Dict[str, Any]:
        """Analisa similaridade entre documentos com otimizaÃ§Ã£o de memÃ³ria"""
        try:
            embeddings = self.embeddings[collection_name]
            documents = self.documents[collection_name]
            
            # ğŸš¨ OTIMIZAÃ‡ÃƒO DE MEMÃ“RIA: Limitar nÃºmero de documentos para anÃ¡lise
            total_docs = len(embeddings)
            if total_docs > max_documents:
                logger.warning(f"âš ï¸ ColeÃ§Ã£o muito grande ({total_docs} documentos)")
                logger.info(f"ğŸ’¡ Limitando anÃ¡lise para {max_documents} documentos para economizar memÃ³ria")
                logger.info(f"ğŸ’¡ Use 'max_documents' maior se tiver mais RAM disponÃ­vel")
                
                # Amostragem aleatÃ³ria para economizar memÃ³ria
                import random
                random.seed(42)  # Para reprodutibilidade
                indices = random.sample(range(total_docs), max_documents)
                embeddings_sample = embeddings[indices]
                documents_sample = [documents[i] for i in indices]
                actual_n_samples = min(n_samples, max_documents)
            else:
                embeddings_sample = embeddings
                documents_sample = documents
                actual_n_samples = n_samples
            
            logger.info(f"ğŸ” Analisando similaridade para {len(embeddings_sample)} documentos...")
            
            # Calcular matriz de similaridade (cosseno) com otimizaÃ§Ã£o de memÃ³ria
            try:
                # Normalizar embeddings
                embeddings_norm = embeddings_sample / np.linalg.norm(embeddings_sample, axis=1, keepdims=True)
                
                # Calcular similaridade em chunks para economizar memÃ³ria
                chunk_size = min(100, len(embeddings_sample))
                similarity_matrix = np.zeros((len(embeddings_sample), len(embeddings_sample)), dtype=np.float32)
                
                for i in range(0, len(embeddings_sample), chunk_size):
                    end_i = min(i + chunk_size, len(embeddings_sample))
                    for j in range(0, len(embeddings_sample), chunk_size):
                        end_j = min(j + chunk_size, len(embeddings_sample))
                        chunk_similarity = np.dot(embeddings_norm[i:end_i], embeddings_norm[j:end_j].T)
                        similarity_matrix[i:end_i, j:end_j] = chunk_similarity
                
                logger.info(f"âœ… Matriz de similaridade calculada com sucesso")
                
            except MemoryError as e:
                logger.error(f"âŒ Erro de memÃ³ria ao calcular similaridade: {e}")
                logger.info("ğŸ’¡ Tentando mÃ©todo alternativo com amostragem menor...")
                
                # Fallback: usar apenas uma amostra muito pequena
                max_docs_fallback = min(100, total_docs)
                indices_fallback = random.sample(range(total_docs), max_docs_fallback)
                embeddings_fallback = embeddings[indices_fallback]
                documents_fallback = [documents[i] for i in indices_fallback]
                
                embeddings_norm_fallback = embeddings_fallback / np.linalg.norm(embeddings_fallback, axis=1, keepdims=True)
                similarity_matrix = np.dot(embeddings_norm_fallback, embeddings_norm_fallback.T)
                embeddings_sample = embeddings_fallback
                documents_sample = documents_fallback
                actual_n_samples = min(n_samples, max_docs_fallback)
                
                logger.info(f"âœ… Usando amostra reduzida de {max_docs_fallback} documentos")
            
            # Encontrar documentos mais similares
            np.fill_diagonal(similarity_matrix, 0)  # Remover auto-similaridade
            
            analysis = {
                'similarity_matrix': similarity_matrix,
                'most_similar_pairs': [],
                'average_similarity': np.mean(similarity_matrix),
                'similarity_std': np.std(similarity_matrix),
                'total_documents_analyzed': len(embeddings_sample),
                'total_documents_original': total_docs,
                'memory_optimized': total_docs > max_documents
            }
            
            # Encontrar pares mais similares
            for i in range(min(actual_n_samples, len(documents_sample))):
                most_similar_idx = np.argmax(similarity_matrix[i])
                similarity_score = similarity_matrix[i][most_similar_idx]
                
                analysis['most_similar_pairs'].append({
                    'doc1': documents_sample[i][:100] + "..." if len(documents_sample[i]) > 100 else documents_sample[i],
                    'doc2': documents_sample[most_similar_idx][:100] + "..." if len(documents_sample[most_similar_idx]) > 100 else documents_sample[most_similar_idx],
                    'similarity': float(similarity_score)
                })
            
            logger.info(f"âœ… AnÃ¡lise de similaridade concluÃ­da para '{collection_name}'")
            logger.info(f"   - Documentos analisados: {len(embeddings_sample)}/{total_docs}")
            logger.info(f"   - Similaridade mÃ©dia: {analysis['average_similarity']:.3f}")
            logger.info(f"   - Desvio padrÃ£o: {analysis['similarity_std']:.3f}")
            if analysis['memory_optimized']:
                logger.info(f"   - âš¡ OtimizaÃ§Ã£o de memÃ³ria aplicada")
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ Erro na anÃ¡lise de similaridade: {e}")
            if "Unable to allocate" in str(e):
                logger.error("ğŸ’¡ DICA: ColeÃ§Ã£o muito grande para anÃ¡lise completa")
                logger.info("ğŸ’¡ SoluÃ§Ãµes:")
                logger.info("   1. Use opÃ§Ã£o 5 (RelatÃ³rio Completo) que otimiza automaticamente")
                logger.info("   2. Reduza o nÃºmero de documentos na coleÃ§Ã£o")
                logger.info("   3. Execute em um sistema com mais RAM")
            return None
    
    def create_similarity_heatmap(self, collection_name: str, analysis: Dict[str, Any]) -> go.Figure:
        """Cria heatmap da matriz de similaridade"""
        try:
            similarity_matrix = analysis['similarity_matrix']
            
            # Criar heatmap
            fig = go.Figure(data=go.Heatmap(
                z=similarity_matrix,
                colorscale='Viridis',
                zmid=0.5,
                colorbar=dict(title="Similaridade (Cosseno)")
            ))
            
            fig.update_layout(
                title=f"Matriz de Similaridade - {collection_name}",
                xaxis_title="Documento",
                yaxis_title="Documento",
                width=800,
                height=600
            )
            
            logger.info(f"âœ… Heatmap de similaridade criado para '{collection_name}'")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ Erro ao criar heatmap: {e}")
            return None
    
    def export_visualization(self, fig: go.Figure, filename: str, format: str = "html"):
        """Exporta visualizaÃ§Ã£o para arquivo"""
        try:
            if format.lower() == "html":
                fig.write_html(f"{filename}.html")
                logger.info(f"âœ… VisualizaÃ§Ã£o exportada para: {filename}.html")
            elif format.lower() == "png":
                fig.write_image(f"{filename}.png")
                logger.info(f"âœ… VisualizaÃ§Ã£o exportada para: {filename}.png")
            elif format.lower() == "pdf":
                fig.write_image(f"{filename}.pdf")
                logger.info(f"âœ… VisualizaÃ§Ã£o exportada para: {filename}.pdf")
            else:
                logger.warning(f"âš ï¸ Formato nÃ£o suportado: {format}")
                
        except Exception as e:
            logger.error(f"âŒ Erro ao exportar visualizaÃ§Ã£o: {e}")
    
    def generate_report(self, collection_name: str, output_dir: str = "visualizations"):
        """Gera relatÃ³rio completo de visualizaÃ§Ãµes"""
        try:
            output_path = Path(output_dir)
            output_path.mkdir(exist_ok=True)
            
            logger.info(f"ğŸ“Š Gerando relatÃ³rio completo para '{collection_name}'...")
            
            # 1. VisualizaÃ§Ã£o 3D com PCA
            fig_3d_pca = self.create_3d_scatter(collection_name, "pca")
            if fig_3d_pca:
                self.export_visualization(fig_3d_pca, output_path / f"{collection_name}_3d_pca")
            
            # 2. VisualizaÃ§Ã£o 3D com UMAP
            fig_3d_umap = self.create_3d_scatter(collection_name, "umap")
            if fig_3d_umap:
                self.export_visualization(fig_3d_umap, output_path / f"{collection_name}_3d_umap")
            
            # 3. ComparaÃ§Ã£o 2D
            fig_2d = self.create_2d_visualizations(collection_name)
            if fig_2d:
                self.export_visualization(fig_2d, output_path / f"{collection_name}_2d_comparison")
            
            # 4. AnÃ¡lise de similaridade
            analysis = self.analyze_similarity(collection_name)
            if analysis:
                # Salvar dados de anÃ¡lise
                with open(output_path / f"{collection_name}_similarity_analysis.json", 'w', encoding='utf-8') as f:
                    json.dump({
                        'average_similarity': analysis['average_similarity'],
                        'similarity_std': analysis['similarity_std'],
                        'most_similar_pairs': analysis['most_similar_pairs']
                    }, f, indent=2, ensure_ascii=False)
                
                # Criar heatmap
                fig_heatmap = self.create_similarity_heatmap(collection_name, analysis)
                if fig_heatmap:
                    self.export_visualization(fig_heatmap, output_path / f"{collection_name}_similarity_heatmap")
            
            # 5. RelatÃ³rio HTML
            self.create_html_report(collection_name, output_path, analysis)
            
            logger.info(f"âœ… RelatÃ³rio completo gerado em: {output_path}")
            
        except Exception as e:
            logger.error(f"âŒ Erro ao gerar relatÃ³rio: {e}")
    
    def create_html_report(self, collection_name: str, output_path: Path, analysis: Dict[str, Any]):
        """Cria relatÃ³rio HTML completo"""
        try:
            html_content = f"""
            <!DOCTYPE html>
            <html lang="pt-BR">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>RelatÃ³rio de VisualizaÃ§Ã£o - {collection_name}</title>
                <style>
                    body {{ font-family: Arial, sans-serif; margin: 20px; }}
                    .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; }}
                    .section {{ margin: 20px 0; padding: 20px; border: 1px solid #ddd; border-radius: 8px; }}
                    .metric {{ display: inline-block; margin: 10px; padding: 15px; background: #f8f9fa; border-radius: 5px; }}
                    .similarity-pair {{ margin: 10px 0; padding: 10px; background: #e9ecef; border-radius: 5px; }}
                    iframe {{ width: 100%; height: 600px; border: none; }}
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>ğŸ” RelatÃ³rio de VisualizaÃ§Ã£o do Banco de Dados Vetorial</h1>
                    <h2>ColeÃ§Ã£o: {collection_name}</h2>
                    <p>Gerado em: {time.strftime('%d/%m/%Y %H:%M:%S')}</p>
                </div>
                
                <div class="section">
                    <h3>ğŸ“Š MÃ©tricas Gerais</h3>
                    <div class="metric">
                        <strong>Total de Documentos:</strong> {len(self.documents[collection_name])}
                    </div>
                    <div class="metric">
                        <strong>DimensÃµes dos Embeddings:</strong> {self.embeddings[collection_name].shape[1]}
                    </div>
                    <div class="metric">
                        <strong>Similaridade MÃ©dia:</strong> {analysis['average_similarity']:.3f if analysis else 'N/A'}
                    </div>
                    <div class="metric">
                        <strong>Desvio PadrÃ£o:</strong> {analysis['similarity_std']:.3f if analysis else 'N/A'}
                    </div>
                </div>
                
                <div class="section">
                    <h3>ğŸ¯ VisualizaÃ§Ã£o 3D - PCA</h3>
                    <iframe src="{collection_name}_3d_pca.html"></iframe>
                </div>
                
                <div class="section">
                    <h3>ğŸŒŒ VisualizaÃ§Ã£o 3D - UMAP</h3>
                    <iframe src="{collection_name}_3d_umap.html"></iframe>
                </div>
                
                <div class="section">
                    <h3>ğŸ“ˆ ComparaÃ§Ã£o de MÃ©todos 2D</h3>
                    <iframe src="{collection_name}_2d_comparison.html"></iframe>
                </div>
                
                <div class="section">
                    <h3>ğŸ”¥ Matriz de Similaridade</h3>
                    <iframe src="{collection_name}_similarity_heatmap.html"></iframe>
                </div>
                
                <div class="section">
                    <h3>ğŸ”— Documentos Mais Similares</h3>
                    {self._generate_similarity_html(analysis) if analysis else '<p>AnÃ¡lise nÃ£o disponÃ­vel</p>'}
                </div>
            </body>
            </html>
            """
            
            with open(output_path / f"{collection_name}_report.html", 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"âœ… RelatÃ³rio HTML criado: {output_path / f'{collection_name}_report.html'}")
            
        except Exception as e:
            logger.error(f"âŒ Erro ao criar relatÃ³rio HTML: {e}")
    
    def _generate_similarity_html(self, analysis: Dict[str, Any]) -> str:
        """Gera HTML para pares similares"""
        html = ""
        for pair in analysis['most_similar_pairs'][:10]:  # Top 10
            html += f"""
            <div class="similarity-pair">
                <strong>Similaridade: {pair['similarity']:.3f}</strong><br>
                <strong>Doc 1:</strong> {pair['doc1']}<br>
                <strong>Doc 2:</strong> {pair['doc2']}
            </div>
            """
        return html


def get_user_input(prompt: str, valid_options: List[str] = None, input_type: str = "text") -> Any:
    """FunÃ§Ã£o auxiliar para obter entrada do usuÃ¡rio com validaÃ§Ã£o"""
    while True:
        try:
            if input_type == "int":
                user_input = int(input(prompt))
                if valid_options and user_input not in valid_options:
                    print(f"âŒ Por favor, escolha uma opÃ§Ã£o vÃ¡lida: {valid_options}")
                    continue
                return user_input
            elif input_type == "float":
                return float(input(prompt))
            elif input_type == "bool":
                user_input = input(prompt).lower().strip()
                if user_input in ['s', 'sim', 'y', 'yes', 'true', '1']:
                    return True
                elif user_input in ['n', 'nÃ£o', 'nao', 'no', 'false', '0']:
                    return False
                else:
                    print("âŒ Por favor, responda com 's' (sim) ou 'n' (nÃ£o)")
                    continue
            else:
                user_input = input(prompt).strip()
                if not user_input:
                    print("âŒ Por favor, digite algo vÃ¡lido")
                    continue
                return user_input
        except ValueError:
            print("âŒ Entrada invÃ¡lida. Tente novamente.")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Interrompido pelo usuÃ¡rio")
            sys.exit(0)


def main():
    """FunÃ§Ã£o principal para executar o visualizador"""
    print("ğŸ” Visualizador 3D do Banco de Dados Vetorial")
    print("=" * 60)
    print("ğŸ“– Este programa permite visualizar e analisar o banco de dados vetorial")
    print("   do sistema RAG em 3D, incluindo clustering e anÃ¡lise de similaridade.")
    print()
    
    # Inicializar visualizador
    visualizer = VectorDBVisualizer()
    
    # Conectar ao ChromaDB
    print("ğŸ”Œ Conectando ao banco de dados vetorial...")
    if not visualizer.connect_to_chromadb():
        print("âŒ Falha ao conectar ao ChromaDB")
        print("ğŸ’¡ Verifique se o diretÃ³rio 'data/.chromadb' existe e contÃ©m dados vÃ¡lidos")
        return
    
    # Listar coleÃ§Ãµes disponÃ­veis
    collections = visualizer.client.list_collections()
    if not collections:
        print("âŒ Nenhuma coleÃ§Ã£o encontrada no banco de dados")
        print("ğŸ’¡ O banco de dados pode estar vazio ou nÃ£o foi inicializado corretamente")
        return
    
    print(f"\nğŸ“š ColeÃ§Ãµes disponÃ­veis no banco de dados:")
    for i, collection in enumerate(collections):
        doc_count = collection.count()
        print(f"   {i+1}. {collection.name} ({doc_count} documentos)")
    
    # Selecionar coleÃ§Ã£o com validaÃ§Ã£o
    print(f"\nğŸ¯ Selecione uma coleÃ§Ã£o para visualizar:")
    print("   ğŸ’¡ Digite o nÃºmero da coleÃ§Ã£o desejada")
    
    try:
        choice = get_user_input(
            f"   Escolha (1-{len(collections)}): ", 
            list(range(1, len(collections) + 1)), 
            "int"
        )
        
        selected_collection = collections[choice - 1].name
        print(f"âœ… ColeÃ§Ã£o selecionada: {selected_collection}")
        
    except (ValueError, IndexError):
        print("âŒ Escolha invÃ¡lida")
        return
    
    # Carregar dados da coleÃ§Ã£o
    print(f"\nğŸ“¥ Carregando dados da coleÃ§Ã£o '{selected_collection}'...")
    if not visualizer.load_collection_data(selected_collection):
        print("âŒ Falha ao carregar dados da coleÃ§Ã£o")
        return
    
    print(f"âœ… Dados carregados com sucesso!")
    print(f"   ğŸ“Š Total de documentos: {len(visualizer.documents[selected_collection])}")
    print(f"   ğŸ§  DimensÃµes dos embeddings: {visualizer.embeddings[selected_collection].shape[1]}")
    
    # Menu principal de opÃ§Ãµes
    while True:
        print(f"\nğŸ”§ Menu de VisualizaÃ§Ãµes - {selected_collection}")
        print("=" * 50)
        print("1. ğŸ¯ VisualizaÃ§Ã£o 3D (PCA)")
        print("   ğŸ’¡ Mostra documentos em 3D usando AnÃ¡lise de Componentes Principais")
        print("   ğŸ“Š Inclui clustering automÃ¡tico dos documentos")
        print()
        print("2. ğŸŒŒ VisualizaÃ§Ã£o 3D (UMAP)")
        print("   ğŸ’¡ VisualizaÃ§Ã£o 3D usando UMAP para melhor preservaÃ§Ã£o de estrutura")
        print("   ğŸ¨ Ideal para anÃ¡lise de clusters e relacionamentos")
        print()
        print("3. ğŸ“ˆ ComparaÃ§Ã£o 2D (PCA, t-SNE, UMAP)")
        print("   ğŸ’¡ Compara diferentes mÃ©todos de reduÃ§Ã£o de dimensionalidade")
        print("   ğŸ” Ãštil para escolher o melhor mÃ©todo para seus dados")
        print()
        print("4. ğŸ”— AnÃ¡lise de Similaridade")
        print("   ğŸ’¡ Analisa como os documentos se relacionam entre si")
        print("   ğŸ“Š Inclui matriz de similaridade e pares mais similares")
        print()
        print("5. ğŸ“Š Gerar RelatÃ³rio Completo")
        print("   ğŸ’¡ Cria todas as visualizaÃ§Ãµes e salva em arquivos")
        print("   ğŸ“ Salva em HTML, PNG e PDF para uso posterior")
        print()
        print("6. ğŸšª Sair")
        print("   ğŸ’¡ Encerra o programa")
        print()
        
        try:
            option = get_user_input("ğŸ¯ Escolha uma opÃ§Ã£o (1-6): ", list(range(1, 7)), "int")
            
            if option == 1:
                print(f"\nğŸ¯ Criando visualizaÃ§Ã£o 3D com PCA...")
                print("   ğŸ’¡ PCA preserva a variÃ¢ncia mÃ¡xima dos dados")
                print("   â³ Isso pode levar alguns segundos para coleÃ§Ãµes grandes...")
                
                fig = visualizer.create_3d_scatter(selected_collection, "pca")
                if fig:
                    print("âœ… VisualizaÃ§Ã£o 3D criada com sucesso!")
                    print("   ğŸ–±ï¸ Use o mouse para rotacionar, zoom e pan")
                    print("   ğŸ“± Toque e arraste em dispositivos touch")
                    fig.show()
                    
                    save = get_user_input("ğŸ’¾ Salvar visualizaÃ§Ã£o? (s/n): ", input_type="bool")
                    if save:
                        filename = get_user_input("ğŸ“ Nome do arquivo (sem extensÃ£o): ")
                        if filename:
                            visualizer.export_visualization(fig, filename, "html")
                            print(f"âœ… VisualizaÃ§Ã£o salva como: {filename}.html")
                else:
                    print("âŒ Falha ao criar visualizaÃ§Ã£o 3D")
            
            elif option == 2:
                print(f"\nğŸŒŒ Criando visualizaÃ§Ã£o 3D com UMAP...")
                print("   ğŸ’¡ UMAP preserva melhor a estrutura local dos dados")
                print("   â³ Processando... (pode demorar para coleÃ§Ãµes grandes)")
                
                fig = visualizer.create_3d_scatter(selected_collection, "umap")
                if fig:
                    print("âœ… VisualizaÃ§Ã£o 3D UMAP criada com sucesso!")
                    print("   ğŸ–±ï¸ Use o mouse para rotacionar, zoom e pan")
                    print("   ğŸ“± Toque e arraste em dispositivos touch")
                    fig.show()
                    
                    save = get_user_input("ğŸ’¾ Salvar visualizaÃ§Ã£o? (s/n): ", input_type="bool")
                    if save:
                        filename = get_user_input("ğŸ“ Nome do arquivo (sem extensÃ£o): ")
                        if filename:
                            visualizer.export_visualization(fig, filename, "html")
                            print(f"âœ… VisualizaÃ§Ã£o salva como: {filename}.html")
                else:
                    print("âŒ Falha ao criar visualizaÃ§Ã£o 3D UMAP")
            
            elif option == 3:
                print(f"\nğŸ“ˆ Criando comparaÃ§Ã£o de mÃ©todos 2D...")
                print("   ğŸ’¡ Comparando PCA, t-SNE e UMAP para 2 dimensÃµes")
                print("   â³ Processando... (pode demorar para coleÃ§Ãµes grandes)")
                
                fig = visualizer.create_2d_visualizations(selected_collection)
                if fig:
                    print("âœ… ComparaÃ§Ã£o 2D criada com sucesso!")
                    print("   ğŸ“Š PCA: Preserva variÃ¢ncia global")
                    print("   ğŸ¯ t-SNE: Foca em estrutura local")
                    print("   ğŸŒŒ UMAP: Equilibra local e global")
                    fig.show()
                    
                    save = get_user_input("ğŸ’¾ Salvar comparaÃ§Ã£o? (s/n): ", input_type="bool")
                    if save:
                        filename = get_user_input("ğŸ“ Nome do arquivo (sem extensÃ£o): ")
                        if filename:
                            visualizer.export_visualization(fig, filename, "html")
                            print(f"âœ… ComparaÃ§Ã£o salva como: {filename}.html")
                else:
                    print("âŒ Falha ao criar comparaÃ§Ã£o 2D")
            
            elif option == 4:
                print(f"\nğŸ”— Analisando similaridade entre documentos...")
                print("   ğŸ’¡ Calculando matriz de similaridade usando cosseno")
                print("   â³ Processando...")
                
                analysis = visualizer.analyze_similarity(selected_collection)
                if analysis:
                    print("âœ… AnÃ¡lise de similaridade concluÃ­da!")
                    print(f"\nğŸ“Š MÃ©tricas de Similaridade:")
                    print(f"   - MÃ©dia: {analysis['average_similarity']:.3f}")
                    print(f"   - Desvio PadrÃ£o: {analysis['similarity_std']:.3f}")
                    
                    print(f"\nğŸ”— Top 5 Pares Mais Similares:")
                    for i, pair in enumerate(analysis['most_similar_pairs'][:5]):
                        print(f"   {i+1}. Similaridade: {pair['similarity']:.3f}")
                        print(f"      ğŸ“„ Doc 1: {pair['doc1'][:80]}...")
                        print(f"      ğŸ“„ Doc 2: {pair['doc2'][:80]}...")
                        print()
                    
                    # Criar e mostrar heatmap
                    print("ğŸ”¥ Criando heatmap de similaridade...")
                    fig = visualizer.create_similarity_heatmap(selected_collection, analysis)
                    if fig:
                        print("âœ… Heatmap criado com sucesso!")
                        print("   ğŸ”¥ Cores mais quentes = maior similaridade")
                        print("   â„ï¸ Cores mais frias = menor similaridade")
                        fig.show()
                        
                        save = get_user_input("ğŸ’¾ Salvar heatmap? (s/n): ", input_type="bool")
                        if save:
                            filename = get_user_input("ğŸ“ Nome do arquivo (sem extensÃ£o): ")
                            if filename:
                                visualizer.export_visualization(fig, filename, "html")
                                print(f"âœ… Heatmap salvo como: {filename}.html")
                    else:
                        print("âŒ Falha ao criar heatmap")
                else:
                    print("âŒ Falha na anÃ¡lise de similaridade")
            
            elif option == 5:
                print(f"\nğŸ“Š Gerando relatÃ³rio completo...")
                print("   ğŸ’¡ Criando todas as visualizaÃ§Ãµes disponÃ­veis")
                print("   ğŸ“ Salvando em pasta 'visualizations'")
                print("   â³ Isso pode levar alguns minutos...")
                
                try:
                    visualizer.generate_report(selected_collection)
                    print("âœ… RelatÃ³rio completo gerado com sucesso!")
                    print("   ğŸ“ Pasta: visualizations/")
                    print("   ğŸ“„ Arquivo principal: visualizations/{selected_collection}_report.html")
                    print("   ğŸ¯ Abra o arquivo HTML no seu navegador para ver tudo")
                except Exception as e:
                    print(f"âŒ Erro ao gerar relatÃ³rio: {e}")
            
            elif option == 6:
                print("\nğŸ“š Explicando MÃ©todos de ReduÃ§Ã£o de Dimensionalidade...")
                print("=" * 60)
                
                explanation = """
ğŸ” **O QUE SÃƒO ESSES MÃ‰TODOS E POR QUE SÃƒO IMPORTANTES?**

ğŸ“š **CONTEXTO: O PROBLEMA DOS DADOS VETORIAIS**

Imagine que cada documento do seu banco de dados Ã© como um ponto no espaÃ§o, mas nÃ£o um espaÃ§o normal de 3 dimensÃµes (altura, largura, profundidade). 
Ã‰ um espaÃ§o de MUITAS dimensÃµes - pode ter 1536, 4096 ou atÃ© mais dimensÃµes!

ğŸ’¡ **POR QUE ISSO Ã‰ UM PROBLEMA?**
- Humanos sÃ³ conseguem visualizar 2D ou 3D
- Computadores tÃªm dificuldade com tantas dimensÃµes
- Ã‰ como tentar entender um cubo de 1536 dimensÃµes!

ğŸ¯ **SOLUÃ‡ÃƒO: REDUÃ‡ÃƒO DE DIMENSIONALIDADE**

Os mÃ©todos PCA, UMAP e t-SNE sÃ£o como "tradutores" que pegam esses pontos em muitas dimensÃµes 
e os colocam em 2D ou 3D, mantendo o mÃ¡ximo possÃ­vel de informaÃ§Ã£o importante.

---

ğŸ”§ **PCA (ANÃLISE DE COMPONENTES PRINCIPAIS)**

ğŸ’­ **EXPLICAÃ‡ÃƒO SIMPLES:**
Imagine que vocÃª tem uma foto de um rosto em alta resoluÃ§Ã£o (muitos pixels). 
PCA Ã© como criar uma versÃ£o "resumida" dessa foto, mantendo apenas os detalhes mais importantes.

ğŸ¯ **O QUE FAZ:**
- Pega os dados em muitas dimensÃµes
- Identifica as "direÃ§Ãµes" mais importantes (onde hÃ¡ mais variaÃ§Ã£o)
- Projeta tudo nessas direÃ§Ãµes principais
- Resultado: 2D ou 3D que preserva a "essÃªncia" dos dados

âœ… **VANTAGENS:**
- RÃ¡pido e eficiente
- Preserva a estrutura global dos dados
- Bom para encontrar padrÃµes gerais

âŒ **LIMITAÃ‡Ã•ES:**
- Pode perder detalhes locais importantes
- NÃ£o Ã© muito bom para encontrar grupos pequenos

---

ğŸŒŒ **UMAP (UNIFORM MANIFOLD APPROXIMATION AND PROJECTION)**

ğŸ’­ **EXPLICAÃ‡ÃƒO SIMPLES:**
Imagine que vocÃª tem um mapa de uma cidade com muitas ruas. UMAP Ã© como criar um mapa simplificado 
que mostra os bairros principais e como eles se conectam, mantendo as distÃ¢ncias relativas.

ğŸ¯ **O QUE FAZ:**
- Preserva tanto a estrutura local quanto global
- Cria uma "rede" que conecta pontos similares
- MantÃ©m as relaÃ§Ãµes de proximidade entre documentos

âœ… **VANTAGENS:**
- Preserva melhor a estrutura local dos dados
- Excelente para encontrar clusters (grupos)
- Bom para visualizaÃ§Ã£o interativa
- Mais rÃ¡pido que t-SNE

âŒ **LIMITAÃ‡Ã•ES:**
- Pode ser menos estÃ¡vel que PCA
- ParÃ¢metros podem afetar o resultado

---

ğŸ¯ **T-SNE (T-DISTRIBUTED STOCHASTIC NEIGHBOR EMBEDDING)**

ğŸ’­ **EXPLICAÃ‡ÃƒO SIMPLES:**
Imagine que vocÃª tem um grupo de pessoas em uma sala. T-SNE Ã© como reorganizar essas pessoas 
em uma sala menor, colocando amigos prÃ³ximos uns dos outros e estranhos mais distantes.

ğŸ¯ **O QUE FAZ:**
- Foca na preservaÃ§Ã£o de distÃ¢ncias locais
- Coloca documentos similares prÃ³ximos
- Separa bem grupos diferentes

âœ… **VANTAGENS:**
- Excelente para encontrar clusters
- Preserva muito bem a estrutura local
- Ã“timo para visualizar grupos de documentos similares

âŒ **LIMITAÃ‡Ã•ES:**
- Pode distorcer a estrutura global
- Mais lento que PCA e UMAP
- Resultado pode variar entre execuÃ§Ãµes

---

ğŸš€ **IMPORTÃ‚NCIA NO BANCO DE DADOS VETORIAL**

ğŸ’¡ **POR QUE ISSO Ã‰ CRÃTICO?**

1. **VISUALIZAÃ‡ÃƒO HUMANA:**
   - Humanos sÃ³ conseguem ver 2D/3D
   - Sem reduÃ§Ã£o, Ã© impossÃ­vel "ver" os dados

2. **ANÃLISE DE CLUSTERS:**
   - Documentos similares ficam prÃ³ximos
   - FÃ¡cil identificar grupos de conteÃºdo relacionado

3. **QUALIDADE DOS DADOS:**
   - Revela se os embeddings estÃ£o funcionando bem
   - Mostra se documentos similares estÃ£o realmente prÃ³ximos

4. **DEBUGGING DO SISTEMA:**
   - Identifica problemas na indexaÃ§Ã£o
   - Mostra se o banco estÃ¡ organizado corretamente

5. **OTIMIZAÃ‡ÃƒO:**
   - Ajuda a ajustar parÃ¢metros do sistema
   - Mostra onde melhorar a qualidade dos embeddings

---

ğŸ¨ **COMO INTERPRETAR OS RESULTADOS**

ğŸ” **GRUPOS BEM DEFINIDOS:**
- Documentos similares estÃ£o prÃ³ximos
- Clusters claros e separados
- Sistema funcionando bem

âš ï¸ **GRUPOS DIFUSOS:**
- Documentos similares espalhados
- Clusters mal definidos
- PossÃ­vel problema nos embeddings

ğŸ¯ **RECOMENDAÃ‡Ã•ES DE USO:**

- **PCA:** Para visÃ£o geral e anÃ¡lise inicial
- **UMAP:** Para anÃ¡lise detalhada e interativa
- **T-SNE:** Para encontrar grupos especÃ­ficos

---

ğŸ’¡ **DICA IMPORTANTE:**
Esses mÃ©todos nÃ£o "criam" informaÃ§Ã£o - eles apenas reorganizam o que jÃ¡ existe. 
Se seus documentos nÃ£o estÃ£o bem organizados no espaÃ§o vetorial original, 
a reduÃ§Ã£o de dimensionalidade nÃ£o vai "consertar" isso!

---

ğŸ¯ **NO SEU CASO ESPECÃFICO:**

VocÃª tem uma coleÃ§Ã£o com {doc_count} documentos, cada um representado por um vetor de {embedding_dims} dimensÃµes.

Isso significa que:
- Cada documento Ã© um ponto em um espaÃ§o de {embedding_dims} dimensÃµes
- Ã‰ impossÃ­vel "ver" essa estrutura sem reduÃ§Ã£o de dimensionalidade
- Os mÃ©todos PCA, UMAP e t-SNE vÃ£o te permitir "ver" como seus documentos se organizam
- VocÃª poderÃ¡ identificar se documentos sobre o mesmo tema estÃ£o realmente prÃ³ximos
- PoderÃ¡ ver se hÃ¡ problemas na organizaÃ§Ã£o do seu banco vetorial

---

ğŸš€ **PRÃ“XIMOS PASSOS:**

1. **Teste PCA primeiro** (opÃ§Ã£o 1) - para visÃ£o geral
2. **Teste UMAP** (opÃ§Ã£o 2) - para anÃ¡lise detalhada
3. **Compare os mÃ©todos** (opÃ§Ã£o 3) - para entender as diferenÃ§as
4. **Analise similaridade** (opÃ§Ã£o 4) - para ver relacionamentos
5. **Gere relatÃ³rio completo** (opÃ§Ã£o 5) - para ter tudo salvo
                """.format(
                    doc_count=len(visualizer.documents[selected_collection]),
                    embedding_dims=visualizer.embeddings[selected_collection].shape[1]
                )
                
                # Mostrar explicaÃ§Ã£o em partes para facilitar leitura
                lines = explanation.strip().split('\n')
                for line in lines:
                    if line.strip():
                        print(line)
                    else:
                        print()
                    
                    # Pausa para facilitar leitura
                    if line.startswith('---'):
                        input("\nâ¸ï¸ Pressione ENTER para continuar...")
                
                print("\nâœ… ExplicaÃ§Ã£o concluÃ­da!")
                print("ğŸ’¡ Agora vocÃª entende por que esses mÃ©todos sÃ£o importantes!")
                print("ğŸ¯ Use as opÃ§Ãµes 1-5 para explorar seu banco de dados vetorial")
            
            elif option == 7:
                print("\nğŸ‘‹ Encerrando o visualizador...")
                print("   ğŸ’¡ Obrigado por usar o sistema de visualizaÃ§Ã£o!")
                print("   ğŸ“ Lembre-se de verificar a pasta 'visualizations' para os arquivos salvos")
                break
            
            else:
                print("âŒ OpÃ§Ã£o invÃ¡lida. Por favor, escolha de 1 a 6.")
                
        except ValueError as e:
            print(f"âŒ Erro de entrada: {e}")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Interrompido pelo usuÃ¡rio")
            break
        except Exception as e:
            print(f"âŒ Erro inesperado: {e}")
            print("ğŸ’¡ Tente novamente ou escolha outra opÃ§Ã£o")


if __name__ == "__main__":
    main()
