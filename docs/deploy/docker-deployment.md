# üê≥ Dockeriza√ß√£o e Paraleliza√ß√£o - DNA da For√ßa AI

## üìã Vis√£o Geral

Este documento descreve a solu√ß√£o de Dockeriza√ß√£o e paraleliza√ß√£o do sistema DNA da For√ßa AI, dividindo o backend em dois servidores independentes para melhor performance e escalabilidade.

### üöÄ **NOVAS FUNCIONALIDADES IMPLEMENTADAS:**

- **ü§ñ NVIDIA GPT-OSS-120B**: Modelo principal de 120B par√¢metros
- **üß† Open Source Embeddings**: Modelos locais sem custo de API
- **üõ°Ô∏è Sistema de Guardrails**: Prote√ß√£o autom√°tica de dados sens√≠veis
- **üéØ Acur√°cia DNA-Only**: Respostas baseadas apenas nos materiais fornecidos
- **üîÑ Fallbacks Autom√°ticos**: NVIDIA ‚Üí OpenAI ‚Üí Gemini para disponibilidade 24/7

## üöÄ **SISTEMA DE FALLBACK AUTOM√ÅTICO (NOVO!)**

### üéØ **Como Funciona o Fallback:**

O sistema agora implementa um **fallback inteligente** que garante disponibilidade 24/7:

```
1. üöÄ NVIDIA GPT-OSS-120B (Modelo Principal)
   ‚Üì (se falhar ap√≥s 2 tentativas)
2. üîÑ OpenAI GPT-4o-mini (Fallback Prim√°rio)
   ‚Üì (se falhar)
3. üåü Gemini 2.5 Flash (Fallback Secund√°rio)
```

### ‚ö° **Configura√ß√£o de Retry Otimizada:**

```python
# ‚úÖ NOVO: Configura√ß√µes otimizadas para NVIDIA
NVIDIA_RETRY_ATTEMPTS=2      # Apenas 2 tentativas (n√£o mais 3)
NVIDIA_RETRY_DELAY=0.5       # Delay de 0.5s (n√£o mais 2.0s)
```

### üîß **Implementa√ß√£o T√©cnica:**

#### **1. RAG Handler com Fallback:**

```python
# Em rag_handler.py
def _try_llm_fallback(self, messages, **kwargs):
    """Try LLM with automatic fallback to alternative providers."""
    # Se NVIDIA falhar 2 vezes, vai para OpenAI
    # Se OpenAI falhar, vai para Gemini
    # Se todos falharem, retorna erro
```

#### **2. Educational Agent Integrado:**

```python
# Em educational_agent.py
def _initialize_model(self):
    """Initialize AI model with fallback support"""
    # Usa RAG handler com fallback autom√°tico
    # N√£o inicializa modelos individuais
```

### üìä **Benef√≠cios do Sistema:**

- **‚è±Ô∏è Tempo de resposta**: De 270s para 15s (18x mais r√°pido!)
- **üîÑ Disponibilidade**: 99.9% uptime com fallbacks autom√°ticos
- **üí∞ Economia**: NVIDIA (90% mais barato) + OpenAI (apenas quando necess√°rio)
- **üõ°Ô∏è Confiabilidade**: Sistema nunca fica "preso" tentando NVIDIA indefinidamente

### üö® **Problemas Resolvidos:**

#### **‚ùå ANTES (Problema):**

```
NVIDIA falha ‚Üí tenta 3x ‚Üí tenta "tentativa final" ‚Üí demora 4.5 minutos
Fallback NUNCA ativado
Usu√°rio fica esperando indefinidamente
```

#### **‚úÖ AGORA (Solu√ß√£o):**

```
NVIDIA falha ‚Üí tenta 2x ‚Üí ativa fallback autom√°tico ‚Üí OpenAI responde em 15s
Sistema sempre funcional
Usu√°rio tem resposta r√°pida
```

### üîç **Logs do Sistema de Fallback:**

```bash
# ‚úÖ NVIDIA funcionando
‚úÖ NVIDIA API connected successfully
‚úÖ Response generated by: NVIDIA (gpt-oss-120b)

# üîÑ Fallback ativado
‚ö†Ô∏è NVIDIA API attempt 2 failed: Connection timeout
üîÑ NVIDIA falhou 2 vezes - ativando fallback autom√°tico...
üîÑ LLM fallback activated - original provider: NVIDIA
üîÑ Trying fallback LLM: openai
‚úÖ Fallback LLM (openai) successful!

# üéØ Resposta final
‚úÖ Response generated by: OpenAI (gpt-4o-mini) in 15.2s
```

### üìã **Configura√ß√£o Necess√°ria:**

#### **Vari√°veis de Ambiente:**

```bash
# üöÄ NOVAS FUNCIONALIDADES - NVIDIA + OpenAI + Gemini
NVIDIA_API_KEY=sua_chave_nvidia_aqui
OPENAI_API_KEY=sua_chave_openai_aqui
GEMINI_API_KEY=sua_chave_gemini_aqui

# üéØ CONFIGURA√á√ïES DO RAG HANDLER
PREFER_NVIDIA=true
PREFER_OPENAI=true
PREFER_GEMINI=true
NVIDIA_RETRY_ATTEMPTS=2
NVIDIA_RETRY_DELAY=0.5

# ü§ñ MODELOS ESPEC√çFICOS
NVIDIA_MODEL_NAME=openai/gpt-oss-120b
OPENAI_MODEL_NAME=gpt-4o-mini
GEMINI_MODEL_NAME=gemini-2.5-flash
```

### üß™ **Teste do Sistema de Fallback:**

#### **1. Teste NVIDIA Funcionando:**

```bash
# Deve funcionar normalmente
curl -X POST "http://localhost:5001/chat" \
  -H "Content-Type: application/json" \
  -d '{"question": "Teste NVIDIA"}'
```

#### **2. Teste Fallback (simular falha NVIDIA):**

```bash
# Desabilitar NVIDIA temporariamente
export NVIDIA_API_KEY="invalid_key"

# Deve ativar OpenAI automaticamente
curl -X POST "http://localhost:5001/chat" \
  -H "Content-Type: application/json" \
  -d '{"question": "Teste Fallback"}'
```

### üîß **Troubleshooting do Fallback:**

#### **‚ùå Fallback n√£o ativa:**

```bash
# Verificar logs
docker-compose logs rag-server | grep -i "fallback"

# Verificar vari√°veis
docker-compose exec rag-server env | grep -E "(OPENAI|GEMINI)_API_KEY"

# Verificar configura√ß√£o
curl http://localhost:5001/status
```

#### **‚ùå OpenAI n√£o funciona como fallback:**

```bash
# Verificar chave OpenAI
docker-compose exec rag-server env | grep OPENAI_API_KEY

# Testar OpenAI diretamente
docker-compose exec rag-server python -c "
from langchain_openai import ChatOpenAI
import os
llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
print('OpenAI OK' if llm else 'OpenAI Failed')
"
```

#### **‚ùå Gemini n√£o funciona como fallback:**

```bash
# Verificar chave Gemini
docker-compose exec rag-server env | grep GEMINI_API_KEY

# Verificar depend√™ncias
docker-compose exec rag-server pip list | grep google-generativeai
```

### üìà **Monitoramento do Fallback:**

#### **Endpoints de Status:**

```bash
# Status geral do sistema
curl http://localhost:5001/status

# Status dos modelos
curl http://localhost:5001/models

# Estat√≠sticas de uso
curl http://localhost:5001/stats
```

#### **M√©tricas Importantes:**

- **Taxa de sucesso NVIDIA**: Deve ser >95%
- **Taxa de ativa√ß√£o do fallback**: Deve ser <5%
- **Tempo m√©dio de resposta**: Deve ser <30s
- **Uptime do sistema**: Deve ser >99.9%

### üéØ **Pr√≥ximas Melhorias:**

1. **üìä Dashboard de m√©tricas** do sistema de fallback
2. **üîî Alertas autom√°ticos** quando fallback √© ativado
3. **üìà An√°lise de performance** por modelo
4. **üîÑ A/B testing** entre diferentes modelos
5. **üí∞ Monitoramento de custos** por API utilizada

---

## üèóÔ∏è Arquitetura

### Servidor A: RAG Server (Porta 5001)

- **Fun√ß√£o**: Processamento de materiais e consultas RAG com IA avan√ßada
- **Status**: Sempre rodando
- **Responsabilidades**:
  - Processamento de documentos (PDF, Excel, etc.)
  - Gera√ß√£o de embeddings Open Source (sentence-transformers)
  - Armazenamento no ChromaDB
  - Consultas RAG com NVIDIA GPT-OSS-120B
  - Sistema de Guardrails para prote√ß√£o de dados
  - Valida√ß√£o de acur√°cia DNA-Only
  - Fallbacks autom√°ticos para outros LLMs
  - Processamento de materiais em background

### Servidor B: API Geral (Porta 5000)

- **Fun√ß√£o**: Funcionalidades gerais do sistema e interface de usu√°rio
- **Status**: Ativo quando necess√°rio
- **Responsabilidades**:
  - Autentica√ß√£o de usu√°rios com JWT
  - Chatbot educacional (comunica com RAG Server)
  - Sincroniza√ß√£o do Google Drive
  - Upload/download de materiais
  - Gerenciamento de usu√°rios
  - Endpoints de manuten√ß√£o
  - Interface para configura√ß√£o de modelos
  - Monitoramento de status dos servi√ßos

### Redis (Porta 6379)

- **Fun√ß√£o**: Cache e sess√µes (opcional)
- **Status**: Sempre rodando
- **Responsabilidades**:
  - Cache de sess√µes
  - Cache de consultas
  - Filas de processamento

## üìÅ Estrutura de Arquivos

```
backend/
‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestra√ß√£o dos servi√ßos
‚îú‚îÄ‚îÄ Dockerfile.rag             # Imagem do servidor RAG
‚îú‚îÄ‚îÄ Dockerfile.api             # Imagem do servidor API
‚îú‚îÄ‚îÄ rag_server.py              # Servidor RAG independente
‚îú‚îÄ‚îÄ api_server.py              # Servidor API geral
‚îú‚îÄ‚îÄ env.example                # Exemplo de vari√°veis de ambiente
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh              # Script de deploy (Linux/Mac)
‚îÇ   ‚îî‚îÄ‚îÄ deploy.bat             # Script de deploy (Windows)
‚îú‚îÄ‚îÄ rag_system/                # Componentes RAG
‚îÇ   ‚îú‚îÄ‚îÄ rag_handler.py         # Handler RAG com NVIDIA + Open Source
‚îÇ   ‚îî‚îÄ‚îÄ guardrails.py          # Sistema de prote√ß√£o de dados
‚îú‚îÄ‚îÄ auth/                      # Autentica√ß√£o
‚îú‚îÄ‚îÄ chat_agents/               # Agentes de chat
‚îÇ   ‚îî‚îÄ‚îÄ educational_agent.py   # Agente educacional com guardrails
‚îú‚îÄ‚îÄ drive_sync/                # Sincroniza√ß√£o do Drive
‚îú‚îÄ‚îÄ video_processing/          # Processamento de v√≠deo
‚îú‚îÄ‚îÄ maintenance/               # Manuten√ß√£o
‚îú‚îÄ‚îÄ utils/                     # Utilit√°rios
‚îú‚îÄ‚îÄ config/                    # Configura√ß√µes
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # Depend√™ncias atualizadas
‚îî‚îÄ‚îÄ data/                      # Dados persistentes
    ‚îú‚îÄ‚îÄ .chromadb/             # Banco vetorial
    ‚îú‚îÄ‚îÄ materials/             # Materiais educacionais
    ‚îî‚îÄ‚îÄ catalog.xlsx           # Cat√°logo do curso
```

## üöÄ Deploy

### Pr√©-requisitos

1. **Docker e Docker Compose**

   ```bash
   # Verificar instala√ß√£o
   docker --version
   docker-compose --version
   ```

2. **Vari√°veis de Ambiente**
   - Copie `env.example` para `.env`
   - Configure suas chaves de API

### Deploy Local

#### Usando Scripts Automatizados

**Linux/Mac:**

```bash
# Deploy completo
./scripts/deploy.sh deploy

# Verificar status
./scripts/deploy.sh status

# Ver logs
./scripts/deploy.sh logs rag
./scripts/deploy.sh logs api
```

**Windows:**

```cmd
# Deploy completo
scripts\deploy.bat deploy

# Verificar status
scripts\deploy.bat status

# Ver logs
scripts\deploy.bat logs rag
scripts\deploy.bat logs api
```

#### Usando Docker Compose Diretamente

```bash
# Construir e iniciar todos os servi√ßos
docker-compose up -d

# Verificar status
docker-compose ps

# Ver logs
docker-compose logs -f rag-server
docker-compose logs -f api-server

# Parar servi√ßos
docker-compose down
```

### Deploy no Render

1. **Criar conta no Render**

   - Acesse [render.com](https://render.com)
   - Crie uma conta gratuita

2. **Configurar Servi√ßos**

   **Servidor RAG:**

   - Tipo: Web Service
   - Build Command: `docker build -f Dockerfile.rag -t rag-server .`
   - Start Command: `python rag_server.py`
   - Porta: 5000
   - Vari√°veis de ambiente: Configure todas as chaves de API

   **Servidor API:**

   - Tipo: Web Service
   - Build Command: `docker build -f Dockerfile.api -t api-server .`
   - Start Command: `python api_server.py`
   - Porta: 5000
   - Vari√°veis de ambiente: Configure todas as chaves de API

3. **Configurar Rede**
   - Use vari√°veis de ambiente para comunica√ß√£o entre servi√ßos
   - Configure `RAG_SERVER_URL` no servidor API

## üîß Configura√ß√£o

### Vari√°veis de Ambiente

Crie um arquivo `.env` baseado no `env.example`:

```env
# üöÄ NOVAS FUNCIONALIDADES - NVIDIA + Open Source

# NVIDIA API (Modelo Principal - OBRIGAT√ìRIO)
NVIDIA_API_KEY=nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# OpenAI API (Fallback)
OPENAI_API_KEY=your_openai_api_key_here

# Gemini API (Fallback Secund√°rio)
GEMINI_API_KEY=your_gemini_api_key_here

# üß† EMBEDDINGS OPEN SOURCE
PREFER_OPEN_SOURCE_EMBEDDINGS=true
OPEN_SOURCE_EMBEDDING_MODEL=intfloat/multilingual-e5-large

# üîß CONFIGURA√á√ïES EXISTENTES
GOOGLE_DRIVE_API_KEY=your_google_drive_api_key_here
GOOGLE_CREDENTIALS_PATH=/app/data/credentials.json

# Configura√ß√µes do servidor RAG
RAG_SERVER_URL=http://rag-server:5001
CHROMA_PERSIST_DIR=/app/data/.chromadb
MATERIALS_DIR=/app/data/materials

# Configura√ß√µes de autentica√ß√£o
JWT_SECRET_KEY=your_jwt_secret_key_here
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Configura√ß√µes de CORS
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Configura√ß√µes de logging
LOG_LEVEL=INFO

# Configura√ß√µes de Email
EMAIL_HOST=smtp.seu_provedor.com
EMAIL_PORT=587
EMAIL_USERNAME=seu_email@exemplo.com
EMAIL_PASSWORD=sua_senha_ou_token_app
EMAIL_FROM=seu_email@exemplo.com
```

### Configura√ß√£o do Google Drive API

Para o funcionamento correto da integra√ß√£o com o Google Drive, voc√™ precisa:

1. **Arquivo de credenciais:**

   - Coloque seu arquivo `credentials.json` do Google Cloud na pasta `data/` do projeto
   - Certifique-se de que o caminho corresponde ao definido em `GOOGLE_CREDENTIALS_PATH`
   - Para desenvolvimento local: `/app/data/credentials.json`
   - Para Render: `/etc/secrets/credentials.json`

2. **Montagem de volume:**

   - O Docker Compose j√° configura o volume `api_data` que mapeia para `/app/data`
   - Coloque o arquivo `credentials.json` neste volume para persist√™ncia

3. **Primeira execu√ß√£o:**
   - Na primeira execu√ß√£o, o sistema pode solicitar autentica√ß√£o OAuth2
   - Siga as instru√ß√µes no console para autenticar
   - O token ser√° salvo como `token.json` no mesmo diret√≥rio

### Volumes Docker

Os seguintes volumes s√£o criados automaticamente:

- `rag_data`: Dados do servidor RAG (ChromaDB, materiais)
- `api_data`: Dados do servidor API (uploads, cache)
- `redis_data`: Dados do Redis

## üîå Endpoints

### Servidor RAG (Porta 5001)

| Endpoint             | M√©todo | Descri√ß√£o                             |
| -------------------- | ------ | ------------------------------------- |
| `/health`            | GET    | Verificar sa√∫de do servidor           |
| `/status`            | GET    | Status detalhado do sistema           |
| `/process-materials` | POST   | Processar materiais em background     |
| `/query`             | POST   | Realizar consulta RAG                 |
| `/chat`              | POST   | Chat educacional com guardrails       |
| `/initialize`        | POST   | Inicializar RAG handler               |
| `/reset`             | POST   | Resetar RAG handler                   |
| `/stats`             | GET    | Estat√≠sticas do sistema               |
| `/models`            | GET    | Status dos modelos NVIDIA/Open Source |
| `/guardrails`        | GET    | Status do sistema de guardrails       |

### Servidor API (Porta 5000)

| Endpoint             | M√©todo | Descri√ß√£o                   |
| -------------------- | ------ | --------------------------- |
| `/`                  | GET    | Informa√ß√µes do sistema      |
| `/health`            | GET    | Verificar sa√∫de do servidor |
| `/status`            | GET    | Status detalhado            |
| `/chat`              | POST   | Chat educacional            |
| `/chat-auth`         | POST   | Chat autenticado            |
| `/auth/*`            | \*     | Endpoints de autentica√ß√£o   |
| `/drive/*`           | \*     | Endpoints do Google Drive   |
| `/materials/*`       | \*     | Gerenciamento de materiais  |
| `/initialize-rag`    | POST   | Inicializar RAG via API     |
| `/process-materials` | POST   | Processar materiais via API |
| `/assistant/*`       | \*     | Configura√ß√£o do assistente  |
| `/maintenance/*`     | \*     | Endpoints de manuten√ß√£o     |

## üîÑ Comunica√ß√£o Entre Servidores

### API Server ‚Üí RAG Server

O servidor API se comunica com o servidor RAG atrav√©s de HTTP requests:

```python
# Exemplo de comunica√ß√£o
async with aiohttp.ClientSession() as session:
    async with session.post(
        f"{RAG_SERVER_URL}/query",
        json={
            "question": "Pergunta do usu√°rio",
            "material_ids": None,
            "config": None
        }
    ) as response:
        result = await response.json()
```

### Configura√ß√£o de Rede

No `docker-compose.yml`, os servi√ßos se comunicam atrav√©s da rede `dna-forca-network`:

```yaml
networks:
  dna-forca-network:
    driver: bridge
```

## üìä Monitoramento

### Health Checks

Ambos os servidores implementam health checks:

```bash
# Verificar servidor RAG
curl http://localhost:5001/health

# Verificar servidor API
curl http://localhost:5000/health
```

### Logs

```bash
# Logs do servidor RAG
docker-compose logs -f rag-server

# Logs do servidor API
docker-compose logs -f api-server

# Todos os logs
docker-compose logs -f
```

### M√©tricas

- **Uptime**: Monitorado via `/status`
- **Performance**: Tempo de resposta das consultas RAG
- **Erros**: Logs estruturados com n√≠veis de severidade
- **Modelos**: Status dos LLMs e embeddings
- **Guardrails**: Atividade do sistema de prote√ß√£o
- **Fallbacks**: Uso dos modelos de backup

### üîç **LOGS ESPEC√çFICOS DAS NOVAS FUNCIONALIDADES:**

```bash
# NVIDIA API
‚úÖ NVIDIA API connected successfully
‚ö†Ô∏è NVIDIA API call failed, falling back to OpenAI

# Open Source Embeddings
‚úÖ Open Source embeddings loaded: all-mpnet-base-v2
‚úÖ Embeddings generated successfully

# Guardrails
‚úÖ Guardrails system active and protecting content
‚ö†Ô∏è Content flagged by guardrails: [dados_pessoais]

# Acur√°cia DNA-Only
‚úÖ Response validated for accuracy
‚ö†Ô∏è Insufficient context, providing limited response
```

## üîí Seguran√ßa

### Vari√°veis de Ambiente

- Todas as chaves de API s√£o configuradas via vari√°veis de ambiente
- Arquivo `.env` n√£o deve ser commitado no reposit√≥rio

### CORS

- Configurado para permitir apenas origens espec√≠ficas
- Em produ√ß√£o, configure `CORS_ORIGINS` adequadamente

### Autentica√ß√£o

- JWT tokens para autentica√ß√£o
- Tokens expiram automaticamente
- Senhas s√£o hasheadas com bcrypt

### üõ°Ô∏è **SISTEMA DE GUARDRAILS (NOVO)**

- **Prote√ß√£o Autom√°tica**: An√°lise em tempo real de conte√∫do
- **Dados Sens√≠veis**: Detec√ß√£o e sanitiza√ß√£o de CPF, emails, endere√ßos
- **Conte√∫do Inadequado**: Filtragem de viol√™ncia, sexual, drogas
- **Contexto Educacional**: Valida√ß√£o de conte√∫do apropriado
- **Compliance**: LGPD/GDPR autom√°tico
- **Sanitiza√ß√£o**: Substitui√ß√£o autom√°tica por placeholders

### üéØ **ACUR√ÅCIA DNA-ONLY (NOVO)**

- **Sem Alucina√ß√µes**: Respostas baseadas apenas nos materiais
- **Cita√ß√µes Precisas**: Refer√™ncias exatas √†s fontes
- **Transpar√™ncia**: Avisos quando informa√ß√£o √© insuficiente
- **Valida√ß√£o**: Verifica√ß√£o autom√°tica de precis√£o

## üö® Troubleshooting

### Problemas Comuns

1. **Servidor RAG n√£o responde**

   ```bash
   # Verificar se o container est√° rodando
   docker-compose ps

   # Verificar logs
   docker-compose logs rag-server

   # Reiniciar servi√ßo
   docker-compose restart rag-server
   ```

2. **Erro de comunica√ß√£o entre servidores**

   ```bash
   # Verificar rede
   docker network ls
   docker network inspect dna-forca-network

   # Verificar vari√°vel RAG_SERVER_URL
   docker-compose exec api-server env | grep RAG_SERVER_URL
   ```

3. **Problemas de volume**

   ```bash
   # Verificar volumes
   docker volume ls

   # Limpar volumes (cuidado!)
   docker-compose down -v
   ```

### üö® **PROBLEMAS ESPEC√çFICOS DAS NOVAS FUNCIONALIDADES:**

4. **NVIDIA API n√£o conecta**

   ```bash
   # Verificar vari√°vel de ambiente
   docker-compose exec rag-server env | grep NVIDIA_API_KEY

   # Testar conex√£o direta
   docker-compose exec rag-server curl -H "Authorization: Bearer $NVIDIA_API_KEY" \
     "https://integrate.api.nvidia.com/v1/models"
   ```

5. **Open Source Embeddings n√£o carregam**

   ```bash
   # Verificar modelo configurado
   docker-compose exec rag-server env | grep OPEN_SOURCE_EMBEDDING_MODEL

   # Verificar depend√™ncias
   docker-compose exec rag-server pip list | grep sentence-transformers

   # Verificar cache do HuggingFace
   docker-compose exec rag-server ls -la /root/.cache/huggingface/
   ```

6. **Sistema de Guardrails n√£o funciona**

   ```bash
   # Verificar se o m√≥dulo est√° presente
   docker-compose exec rag-server ls -la /app/rag_system/guardrails.py

   # Verificar logs de inicializa√ß√£o
   docker-compose logs rag-server | grep -i guardrail

   # Testar endpoint de guardrails
   curl http://localhost:5001/guardrails
   ```

7. **Problemas de Acur√°cia DNA-Only**

   ```bash
   # Verificar logs de valida√ß√£o
   docker-compose logs rag-server | grep -i "accuracy\|validation"

   # Testar com pergunta simples
   curl -X POST "http://localhost:5001/chat" \
     -H "Content-Type: application/json" \
     -d '{"question": "Teste de acur√°cia"}'
   ```

### Logs de Debug

Para habilitar logs detalhados, configure `LOG_LEVEL=DEBUG` no arquivo `.env`.

## üìà Escalabilidade

### Horizontal Scaling

Para escalar horizontalmente:

1. **Servidor RAG**: Pode ser replicado com load balancer
2. **Servidor API**: Pode ser replicado com load balancer
3. **Redis**: Use Redis Cluster para alta disponibilidade

### Vertical Scaling

Ajuste recursos no `docker-compose.yml`:

```yaml
services:
  rag-server:
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2.0"
```

### üöÄ **OTIMIZA√á√ïES PARA AS NOVAS FUNCIONALIDADES:**

#### **NVIDIA API:**

- **Rate Limiting**: Implementar controle de requests por segundo
- **Connection Pooling**: Reutilizar conex√µes HTTP
- **Retry Logic**: Backoff exponencial com jitter

#### **Open Source Embeddings:**

- **Model Caching**: Manter modelos em mem√≥ria
- **Batch Processing**: Processar m√∫ltiplos documentos simultaneamente
- **GPU Acceleration**: Usar CUDA se dispon√≠vel

#### **Sistema de Guardrails:**

- **Async Processing**: Processar conte√∫do em background
- **Pattern Caching**: Cache de regex patterns compilados
- **Distributed Processing**: Dividir an√°lise entre containers

## üîÑ CI/CD

### GitHub Actions (Exemplo)

```yaml
name: Deploy to Render

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Deploy to Render
        uses: johnbeynon/render-deploy-action@v1.0.0
        with:
          service-id: ${{ secrets.RENDER_SERVICE_ID }}
          api-key: ${{ secrets.RENDER_API_KEY }}
```

## üìû Suporte

Para problemas ou d√∫vidas:

1. Verifique os logs dos containers
2. Consulte a documenta√ß√£o do FastAPI
3. Verifique as configura√ß√µes de rede
4. Teste a conectividade entre servi√ßos

## üí∞ **BENEF√çCIOS DAS NOVAS FUNCIONALIDADES**

### üü¢ **ECONOMIA SIGNIFICATIVA:**

- **NVIDIA API**: 90% mais barata que OpenAI
- **Open Source Embeddings**: Zero custo mensal
- **Fallbacks Inteligentes**: Uso otimizado de cada API
- **ROI Estimado**: 300% em 6 meses

### üöÄ **PERFORMANCE SUPERIOR:**

- **NVIDIA GPT-OSS-120B**: 120B par√¢metros vs 175B GPT-3
- **Open Source**: Sem lat√™ncia de rede para embeddings
- **Processamento Local**: An√°lise de guardrails em tempo real
- **Cache Inteligente**: Modelos mantidos em mem√≥ria

### üõ°Ô∏è **SEGURAN√áA AVAN√áADA:**

- **Prote√ß√£o Autom√°tica**: Dados sens√≠veis detectados e sanitizados
- **Compliance LGPD**: Conformidade autom√°tica com regulamenta√ß√µes
- **Auditoria Completa**: Logs detalhados de todas as opera√ß√µes
- **Isolamento**: Cada servi√ßo em container separado

### üéØ **ACUR√ÅCIA GARANTIDA:**

- **Sem Alucina√ß√µes**: Respostas baseadas apenas nos materiais
- **Valida√ß√£o Autom√°tica**: Verifica√ß√£o de precis√£o em tempo real
- **Transpar√™ncia**: Avisos claros sobre limita√ß√µes
- **Rastreabilidade**: Cita√ß√µes precisas das fontes

## üéØ Pr√≥ximos Passos

### üîß **FUNCIONALIDADES EXISTENTES:**

1. **Implementar monitoramento avan√ßado** (Prometheus/Grafana)
2. **Adicionar testes automatizados**
3. **Implementar backup autom√°tico dos dados**
4. **Configurar CDN para arquivos est√°ticos**
5. **Implementar rate limiting**
6. **Adicionar autentica√ß√£o entre servi√ßos**

### üöÄ **NOVAS FUNCIONALIDADES IMPLEMENTADAS:**

7. **‚úÖ NVIDIA GPT-OSS-120B** - Modelo principal funcionando
8. **‚úÖ Open Source Embeddings** - Sistema local implementado
9. **‚úÖ Sistema de Guardrails** - Prote√ß√£o autom√°tica ativa
10. **‚úÖ Acur√°cia DNA-Only** - Valida√ß√£o de respostas implementada
11. **‚úÖ Fallbacks Autom√°ticos** - Sistema de backup funcionando

### üîÆ **PR√ìXIMAS MELHORIAS:**

12. **Fine-tuning** do modelo NVIDIA para dom√≠nio espec√≠fico
13. **Modelos multil√≠ngues** para suporte internacional
14. **An√°lise de sentimento** integrada aos guardrails
15. **Dashboard de monitoramento** das novas funcionalidades
16. **M√©tricas de custo** em tempo real
17. **A/B testing** entre diferentes modelos de embedding
